"""Oracle Unified Directory (OUD) Quirks.

Copyright (c) 2025 FLEXT Team. All rights reserved.
SPDX-License-Identifier: MIT

Provides OUD-specific quirks for schema, ACL, and entry processing.
"""

from __future__ import annotations

import base64
import operator
import re
from collections.abc import Mapping
from enum import StrEnum
from typing import ClassVar

from flext_core import FlextLogger, FlextResult, FlextRuntime

from flext_ldif.constants import FlextLdifConstants
from flext_ldif.models import FlextLdifModels
from flext_ldif.servers.rfc import FlextLdifServersRfc
from flext_ldif.typings import FlextLdifTypes
from flext_ldif.utilities import FlextLdifUtilities

logger = FlextLogger(__name__)

# Alias for cleaner code - MetadataKeys from Constants
MetaKeys = FlextLdifConstants.MetadataKeys


class FlextLdifServersOud(FlextLdifServersRfc):
    """Oracle Unified Directory (OUD) Quirks."""

    # =========================================================================
    # STANDARDIZED CONSTANTS FOR AUTO-DISCOVERY
    # =========================================================================
    class Constants(FlextLdifServersRfc.Constants):
        """Oracle Unified Directory-specific constants using Python 3.13 patterns.

        Organizes OUD-specific constants using advanced Python 3.13 features:
        - Type aliases for semantic grouping
        - Frozen immutable collections
        - Advanced mapping patterns for zero-cost abstractions
        - Consolidated patterns to reduce code duplication

        All configuration including SERVER_TYPE and PRIORITY are defined here
        following the standardized pattern used across all server implementations.
        """

        # Server identity and priority (defined at Constants level)
        SERVER_TYPE: ClassVar[str] = FlextLdifConstants.ServerTypes.OUD
        PRIORITY: ClassVar[int] = 10  # High priority (OUD is well-known server)

        # LDAP Connection Defaults (RFC 4511 §4.1)
        DEFAULT_PORT: ClassVar[int] = 1389  # OUD default port (non-standard)
        DEFAULT_SSL_PORT: ClassVar[int] = 1636  # OUD default SSL port (non-standard)
        DEFAULT_PAGE_SIZE: ClassVar[int] = 1000  # RFC 2696 Simple Paged Results default

        # Logging and debug constants
        MAX_LOG_LINE_LENGTH: ClassVar[int] = 200  # Maximum length for log line excerpts

        # =====================================================================
        # CORE IDENTITY - Server identification and metadata
        # =====================================================================
        CANONICAL_NAME: ClassVar[str] = "oud"
        ALIASES: ClassVar[frozenset[str]] = frozenset(["oud", "oracle_oud"])

        # =====================================================================
        # CONVERSION CAPABILITIES
        # =====================================================================
        CAN_NORMALIZE_FROM: ClassVar[frozenset[str]] = frozenset(["oud", "rfc"])
        CAN_DENORMALIZE_TO: ClassVar[frozenset[str]] = frozenset(["oud", "rfc"])

        # =====================================================================
        # ACL CONFIGURATION
        # =====================================================================
        ACL_FORMAT: ClassVar[str] = "aci"  # RFC 4876 ACI attribute
        ACL_ATTRIBUTE_NAME: ClassVar[str] = "aci"  # OUD uses standard ACI

        # === ACL METADATA KEYS (Standardized for cross-server conversion) ===
        # Use centralized constants from FlextLdifConstants.MetadataKeys
        # Servers MUST NOT know about each other - only communicate via standardized metadata
        # All metadata keys are defined in FlextLdifConstants.MetadataKeys for consistency

        # === ACL PERMISSIONS (OUD extends RFC) ===
        PERMISSION_SELFWRITE: ClassVar[str] = "selfwrite"
        PERMISSION_SELF_WRITE: ClassVar[str] = "self_write"
        PERMISSION_PROXY: ClassVar[str] = "proxy"
        PERMISSION_ALL: ClassVar[str] = "all"

        # OUD Supported Permissions (extends RFC baseline)
        SUPPORTED_PERMISSIONS: ClassVar[frozenset[str]] = frozenset(
            [
                "read",
                "write",
                "add",
                "delete",
                "search",
                "compare",
                "selfwrite",
                "proxy",
                "all",
            ],
        )

        # === ACL CONSTANTS (Python 3.13 mapping) ===
        ACL_DEFAULT_NAME: ClassVar[str] = "OUD ACL"
        ACL_DEFAULT_TARGETATTR: ClassVar[str] = "*"
        ACL_DEFAULT_VERSION: ClassVar[str] = "version 3.0"
        ACL_VERSION_PREFIX: ClassVar[str] = "(version 3.0"
        ACL_ALLOW_PREFIX: ClassVar[str] = "allow ("
        ACL_ACI_PREFIX: ClassVar[str] = "aci:"
        ACL_DS_CFG_PREFIX: ClassVar[str] = "ds-cfg-"

        # === ACL PREFIX CONSTANTS ===
        ACL_TARGETATTR_PREFIX: ClassVar[str] = "targetattr="
        ACL_TARGETSCOPE_PREFIX: ClassVar[str] = "targetscope="
        ACL_LDAP_URL_PREFIX: ClassVar[str] = "ldap:///"

        # === ACL SUBJECT CONSTANTS ===
        ACL_SELF_SUBJECT: ClassVar[str] = "ldap:///self"
        ACL_ANONYMOUS_SUBJECT: ClassVar[str] = "ldap:///anyone"
        ACL_ANONYMOUS_SUBJECT_ALT: ClassVar[str] = "ldap:///*"

        # === ACL PARSING CONSTANTS (Python 3.13 Mapping) ===
        ACL_NEWLINE_SEPARATOR: ClassVar[str] = "\n"
        ACL_OPS_SEPARATOR: ClassVar[str] = ","
        ACL_ACTION_ALLOW: ClassVar[str] = "allow"
        ACL_ACTION_DENY: ClassVar[str] = "deny"
        ACL_BIND_RULE_KEY_TYPE: ClassVar[str] = "type"
        ACL_BIND_RULE_KEY_VALUE: ClassVar[str] = "value"
        ACL_SUBJECT_TYPE_BIND_RULES: ClassVar[str] = "bind_rules"

        # === ACL BIND RULE TYPES ===
        ACL_BIND_RULE_TYPE_USERDN: ClassVar[str] = "userdn"
        ACL_BIND_RULE_TYPE_GROUPDN: ClassVar[str] = "groupdn"

        # === ACL REGEX PATTERNS (Consolidated) ===
        ACL_USERDN_PATTERN: ClassVar[str] = r'userdn\s*=\s*"ldap:///([^"]+)"'
        ACL_GROUPDN_PATTERN: ClassVar[str] = r'groupdn\s*=\s*"ldap:///([^"]+)"'
        ACL_TARGETATTR_PATTERN: ClassVar[str] = r'\(targetattr\s*(!?=)\s*"([^"]+)"\)'
        ACL_TARGETSCOPE_PATTERN: ClassVar[str] = r'\(targetscope\s*=\s*"([^"]+)"\)'
        ACL_VERSION_ACL_PATTERN: ClassVar[str] = (
            r'version\s+([\d.]+);\s*acl\s+"([^"]+)"'
        )
        ACL_ALLOW_DENY_PATTERN: ClassVar[str] = r"(allow|deny)\s+\(([^)]+)\)"
        ACL_BY_GROUP_PATTERN: ClassVar[str] = r"by\s+group=\"[^\"]+\""
        ACL_BY_STAR_PATTERN: ClassVar[str] = r"by\s+\*"

        # === ACL ADVANCED PATTERNS (RFC 4876 extensions validated against Oracle OUD documentation) ===
        ACL_TARGATTRFILTERS_PATTERN: ClassVar[str] = (
            r'\(targattrfilters\s*=\s*"([^"]+)"\)'
        )
        ACL_TARGETCONTROL_PATTERN: ClassVar[str] = r'\(targetcontrol\s*=\s*"([^"]+)"\)'
        ACL_EXTOP_PATTERN: ClassVar[str] = r'\(extop\s*=\s*"([^"]+)"\)'
        ACL_IP_PATTERN: ClassVar[str] = r'ip\s*=\s*"([^"]+)"'
        ACL_DNS_PATTERN: ClassVar[str] = r'dns\s*=\s*"([^"]+)"'
        ACL_DAYOFWEEK_PATTERN: ClassVar[str] = r'dayofweek\s*=\s*"([^"]+)"'
        ACL_TIMEOFDAY_PATTERN: ClassVar[str] = r'timeofday\s*([<>=!]+)\s*"?(\d+)"?'
        ACL_AUTHMETHOD_PATTERN: ClassVar[str] = r'authmethod\s*=\s*"?(\w+)"?'
        ACL_SSF_PATTERN: ClassVar[str] = r'ssf\s*([<>=!]+)\s*"?(\d+)"?'

        # === ACL BIND RULE TUPLE CONSTANTS ===
        ACL_BIND_RULE_TUPLE_LENGTH: ClassVar[int] = (
            2  # Expected length for (operator, value) tuples
        )

        # === ACL WRITE CONFIGURATIONS (for utility consolidation) ===
        # Bind rules config: (extension_key, format_template, operator_default)
        # extension_key must match FlextLdifConstants.MetadataKeys values
        ACL_BIND_RULES_CONFIG: ClassVar[list[tuple[str, str, str | None]]] = [
            ("bind_ip", 'ip="{value}"', None),
            ("bind_dns", 'dns="{value}"', None),
            ("bind_dayofweek", 'dayofweek="{value}"', None),
            ("bind_timeofday", 'timeofday {operator} "{value}"', "="),
            ("authmethod", 'authmethod = "{value}"', None),
            ("ssf", 'ssf {operator} "{value}"', ">="),
        ]

        # Target extensions config: (extension_key, format_template)
        # extension_key must match FlextLdifConstants.MetadataKeys values
        ACL_TARGET_EXTENSIONS_CONFIG: ClassVar[list[tuple[str, str]]] = [
            ("targattrfilters", '(targattrfilters="{value}")'),
            ("targetcontrol", '(targetcontrol="{value}")'),
            ("extop", '(extop="{value}")'),
        ]

        # NOTE: Alternative ACL format patterns (ACL_FILTER_PATTERN, ACL_CONSTRAINT_PATTERN) REMOVED
        # OUD only handles RFC 4876 ACI format - Alternative format data comes pre-converted via RFC Entry Model

        # === ACL BIND PATTERNS MAPPING (Python 3.13) ===
        ACL_BIND_PATTERNS: ClassVar[Mapping[str, str]] = {
            ACL_BIND_RULE_TYPE_USERDN: ACL_USERDN_PATTERN,
            ACL_BIND_RULE_TYPE_GROUPDN: ACL_GROUPDN_PATTERN,
        }

        # === ACL NORMALIZATION CONTROL ===
        # OUD accepts both "cn=Group,cn=Context" and "cn=Group, cn=Context" formats
        # No normalization needed for roundtrip - preserves original values
        ACL_NORMALIZE_DNS_IN_VALUES: ClassVar[bool] = False

        # =====================================================================
        # SCHEMA CONFIGURATION
        # =====================================================================
        SCHEMA_DN: ClassVar[str] = "cn=schema"

        # === SCHEMA FIELD NAMES ===
        SCHEMA_FIELD_ATTRIBUTE_TYPES: ClassVar[str] = "attributetypes"
        SCHEMA_FIELD_OBJECT_CLASSES: ClassVar[str] = "objectclasses"
        SCHEMA_FIELD_MATCHING_RULES: ClassVar[str] = "matchingrules"
        SCHEMA_FIELD_LDAP_SYNTAXES: ClassVar[str] = "ldapsyntaxes"

        # Schema fields that should be processed with OUD filtering
        SCHEMA_FILTERABLE_FIELDS: ClassVar[frozenset[str]] = frozenset(
            [
                SCHEMA_FIELD_ATTRIBUTE_TYPES,
                SCHEMA_FIELD_OBJECT_CLASSES,
                SCHEMA_FIELD_MATCHING_RULES,
                SCHEMA_FIELD_LDAP_SYNTAXES,
            ],
        )

        # Schema attribute fields that are server-specific
        ATTRIBUTE_FIELDS: ClassVar[frozenset[str]] = frozenset(["x_origin"])

        # ObjectClass requirements specific to OUD
        OBJECTCLASS_REQUIREMENTS: ClassVar[Mapping[str, bool]] = {
            "requires_sup_for_auxiliary": True,
            "allows_multiple_sup": False,
            "requires_explicit_structural": True,
        }

        # Schema attribute transformation constants
        ATTRIBUTE_UNDERSCORE_TO_DASH: ClassVar[str] = "_"
        ATTRIBUTE_DASH_REPLACEMENT: ClassVar[str] = "-"

        # =====================================================================
        # VALIDATION CONFIGURATION - Server-specific validation rules
        # =====================================================================
        DEFAULT_ENCODING: ClassVar[str] = "utf-8"
        ALLOWED_ENCODINGS: ClassVar[tuple[str, ...]] = ("utf-8", "utf-16", "ascii")
        DN_PRESERVE_CASE: ClassVar[bool] = False
        DN_NORMALIZE_TO: ClassVar[str] = "lowercase"
        ACL_REQUIRES_TARGET: ClassVar[bool] = True
        ACL_REQUIRES_SUBJECT: ClassVar[bool] = True
        TRACK_DELETIONS: ClassVar[bool] = True
        TRACK_MODIFICATIONS: ClassVar[bool] = True
        TRACK_CONVERSIONS: ClassVar[bool] = True

        # =====================================================================
        # OPERATIONAL ATTRIBUTES
        # =====================================================================
        OPERATIONAL_ATTRIBUTES: ClassVar[frozenset[str]] = frozenset(
            [
                "createTimestamp",
                "modifyTimestamp",
                "creatorsName",
                "modifiersName",
                "entryUUID",
                "entryDN",
                "subschemaSubentry",
                "hasSubordinates",
                "pwdChangedTime",
                "pwdHistory",
                "pwdFailureTime",
                "ds-sync-hist",
                "ds-sync-state",
                "ds-pwp-account-disabled",
                "ds-cfg-backend-id",
            ],
        )

        # OUD specific operational attributes (subset of OPERATIONAL_ATTRIBUTES)
        OUD_SPECIFIC: ClassVar[frozenset[str]] = frozenset(
            [
                "ds-sync-hist",
                "ds-sync-state",
                "ds-pwp-account-disabled",
                "ds-cfg-backend-id",
                "entryUUID",
            ],
        )

        # Extends RFC PRESERVE_ON_MIGRATION with OUD-specific timestamps
        PRESERVE_ON_MIGRATION: ClassVar[frozenset[str]] = (
            FlextLdifServersRfc.Constants.PRESERVE_ON_MIGRATION
            | frozenset(["pwdChangedTime"])
        )

        # === BOOLEAN ATTRIBUTES (OUD-specific) ===
        # NOTE: orcldasselfmodifiable is OID-specific (Oracle DAS), NOT OUD native
        # OID→OUD conversion handles this via RFC Entry Model metadata
        BOOLEAN_ATTRIBUTES: ClassVar[frozenset[str]] = frozenset(
            [
                "pwdlockout",
                "pwdmustchange",
                "pwdallowuserchange",
                "pwdexpirewarning",
                "pwdgraceauthnlimit",
                "pwdlockoutduration",
                "pwdmaxfailure",
                "pwdminage",
                "pwdmaxage",
                "pwdmaxlength",
                "pwdminlength",
            ],
        )

        # =====================================================================
        # ATTRIBUTE TRANSFORMATIONS (Python 3.13 Mapping)
        # =====================================================================

        # === ATTRIBUTE CASE MAPPING ===
        # lowercase source → proper OUD camelCase
        # NOTE: OUD has ZERO knowledge of OID formats (orclaci, orclentrylevelaci)
        # OID→OUD conversion goes through RFC Entry Model metadata
        ATTRIBUTE_CASE_MAP: ClassVar[Mapping[str, str]] = {
            "uniquemember": "uniqueMember",
            "displayname": "displayName",
            "distinguishedname": "distinguishedName",
            FlextLdifConstants.DictKeys.OBJECTCLASS.lower(): (
                FlextLdifConstants.DictKeys.OBJECTCLASS
            ),
            "memberof": "memberOf",
            "seealsodescription": "seeAlsoDescription",
            "acl": "aci",  # Generic ACL → OUD RFC ACI (matches ACL_ATTRIBUTE_NAME)
        }

        # === ATTRIBUTE NAME TRANSFORMATIONS ===
        # OUD→RFC attribute name transformations (for compatibility)
        ATTRIBUTE_TRANSFORMATION_OUD_TO_RFC: ClassVar[Mapping[str, str]] = {
            "ds-sync-hist": "dsyncHist",  # OUD proprietary
            "ds-pwp-account-disabled": "accountDisabled",  # OUD password policy
            "entryUUID": "entryUUID",  # Standard RFC, OUD version
        }

        # RFC→OUD attribute name transformations (for reverse mapping)
        ATTRIBUTE_TRANSFORMATION_RFC_TO_OUD: ClassVar[Mapping[str, str]] = {
            "dsyncHist": "ds-sync-hist",
            "accountDisabled": "ds-pwp-account-disabled",
            "entryUUID": "entryUUID",
        }

        # === OUD ATTRIBUTE ALIASES ===
        # Attribute aliases for OUD (multiple names for same semantic attribute)
        ATTRIBUTE_ALIASES: ClassVar[Mapping[str, list[str]]] = {
            "cn": ["commonName"],
            "sn": ["surname"],
            "givenName": ["gn"],
            "mail": ["rfc822Mailbox", "emailAddress"],
            "telephoneNumber": ["phone"],
            "uid": ["userid", "username"],
        }

        # =====================================================================
        # ACL SUBJECT TRANSFORMATIONS (Python 3.13 Mapping)
        # =====================================================================

        # Subject type transformations from RFC format to OUD format
        RFC_TO_OUD_SUBJECTS: ClassVar[Mapping[str, tuple[str, str]]] = {
            "group_membership": ("bind_rules", 'userattr="{value}#LDAPURL"'),
            "user_attribute": ("bind_rules", 'userattr="{value}#USERDN"'),
            "group_attribute": ("bind_rules", 'userattr="{value}#GROUPDN"'),
        }

        # Subject type transformations from OUD format back to RFC format
        OUD_TO_RFC_SUBJECTS: ClassVar[Mapping[str, tuple[str, str]]] = {
            "bind_rules": ("group_membership", "{value}"),
        }

        # =====================================================================
        # MATCHING RULE VALIDATIONS & REPLACEMENTS (Python 3.13 Mapping)
        # =====================================================================

        # Matching rules that are invalid for SUBSTR operations
        INVALID_SUBSTR_RULES: ClassVar[Mapping[str, str | None]] = {
            "caseIgnoreMatch": "caseIgnoreSubstringsMatch",  # Common SUBSTR mistake
            "distinguishedNameMatch": None,  # No valid SUBSTR replacement
            "caseIgnoreOrderingMatch": None,  # No SUBSTR variant
            "numericStringMatch": "numericStringSubstringsMatch",  # Corrected
        }

        # Matching rules that need replacement for OUD compatibility
        MATCHING_RULE_REPLACEMENTS: ClassVar[Mapping[str, str]] = {
            "caseIgnoreMatch": "caseIgnoreMatch",  # Keep as-is in OUD
            "caseIgnoreSubstringsMatch": "caseIgnoreSubstringsMatch",  # Standard
        }

        # =====================================================================
        # CATEGORIZATION RULES - OUD-specific entry categorization
        # =====================================================================
        # OUD categorization uses standard RFC objectClasses
        # Priority: users → hierarchy → groups → acl
        # ObjectClasses for each category (RFC-compliant)
        CATEGORY_OBJECTCLASSES: ClassVar[dict[str, frozenset[str]]] = {
            "users": frozenset(
                [
                    "person",
                    "inetOrgPerson",
                    "organizationalPerson",
                ],
            ),
            "hierarchy": frozenset(
                [
                    "organizationalUnit",
                    "organization",
                    "domain",
                    "country",
                    "locality",
                ],
            ),
            "groups": frozenset(
                [
                    "groupOfNames",
                    "groupOfUniqueNames",
                ],
            ),
        }

        # OUD hierarchy priority (RFC standard containers)
        HIERARCHY_PRIORITY_OBJECTCLASSES: ClassVar[frozenset[str]] = frozenset(
            [
                "organizationalUnit",
                "organization",
                "domain",
            ],
        )

        # ACL attributes for OUD
        CATEGORIZATION_ACL_ATTRIBUTES: ClassVar[frozenset[str]] = frozenset(
            [
                "aci",  # RFC 4876 ACI
            ],
        )

        # Categorization priority order for OUD
        # Schema first (always), then acl (OUD-specific ACL attributes), then users, hierarchy, groups, rejected
        CATEGORIZATION_PRIORITY: ClassVar[list[str]] = [
            "schema",
            "acl",
            "users",
            "hierarchy",
            "groups",
            "rejected",
        ]

        # =====================================================================
        # DETECTION PATTERNS - Server type detection rules
        # =====================================================================

        # === DN PREFIXES (used in Entry.can_handle) ===
        DN_PREFIX_CN_CONFIG: ClassVar[str] = "cn=config"
        DN_PREFIX_CN_SCHEMA: ClassVar[str] = "cn=schema"
        DN_PREFIX_CN_DIRECTORY: ClassVar[str] = "cn=directory"
        DN_PREFIX_CN_DS: ClassVar[str] = "cn=ds"

        # DN detection patterns for can_handle - tuple of pattern tuples (OR of ANDs)
        DN_DETECTION_PATTERNS: ClassVar[tuple[tuple[str, ...], ...]] = (
            ("cn=config", "cn=schema"),
            ("cn=config", "cn=directory"),
            ("cn=config", "cn=ds"),
        )

        # Keyword patterns for attribute name detection
        KEYWORD_PATTERNS: ClassVar[tuple[str, ...]] = ("pwd", "password")

        # === DETECTION PATTERNS ===
        # Case-insensitive pattern ((?i) flag) because detector searches in
        # lowercase content
        # NOTE: Renamed from DETECTION_OID_PATTERN to avoid confusion with Oracle Internet Directory (OID)
        # This pattern detects OUD (Oracle Unified Directory) specific attributes
        DETECTION_PATTERN: ClassVar[str] = (
            r"(?i)(ds-sync-|ds-pwp-|ds-cfg-|root dns)"  # OUD-specific attributes
        )
        # Alias for DETECTION_PATTERN (maintained for compatibility with detector service)
        DETECTION_OID_PATTERN: ClassVar[str] = DETECTION_PATTERN
        DETECTION_WEIGHT: ClassVar[int] = (
            14  # Detection confidence weight (increased to overcome
            # OpenLDAP cn=config ambiguity)
        )
        DETECTION_ACL_PREFIX: ClassVar[str] = "ds-cfg-"  # OUD configuration ACL prefix

        # === DETECTION COLLECTIONS (Python 3.13 frozenset) ===
        DETECTION_ATTRIBUTE_PREFIXES: ClassVar[frozenset[str]] = frozenset(
            [
                "ds-",
                "ds-sync",
                "ds-pwp",
                "ds-cfg",
            ],
        )

        DETECTION_ATTRIBUTES: ClassVar[frozenset[str]] = frozenset(
            [
                "ds-sync-hist",
                "ds-sync-state",
                "ds-pwp-account-disabled",
                "ds-cfg-backend-id",
                "ds-privilege-name",
                "entryUUID",
            ],
        )

        DETECTION_OBJECTCLASS_NAMES: ClassVar[frozenset[str]] = frozenset(
            [
                "ds-root-dse",
                "ds-root-dn-user",
                "ds-unbound-id-config",
                "ds-cfg-backend",
            ],
        )

        DETECTION_DN_MARKERS: ClassVar[frozenset[str]] = frozenset(
            [
                "cn=config",
                "cn=tasks",
                "cn=monitor",
            ],
        )

        # === NESTED STRENUM DEFINITIONS ===
        # StrEnum definitions for type-safe permission, action, and encoding handling

        class AclPermission(StrEnum):
            """OUD-specific ACL permissions."""

            READ = "read"
            WRITE = "write"
            ADD = "add"
            DELETE = "delete"
            SEARCH = "search"
            COMPARE = "compare"
            AUTH = "auth"
            ALL = "all"
            NONE = "none"

        class AclAction(StrEnum):
            """OUD ACL action types."""

            ALLOW = "allow"
            DENY = "deny"

        class Encoding(StrEnum):
            """OUD-supported encodings."""

            UTF_8 = "utf-8"
            UTF_16 = "utf-16"
            ASCII = "ascii"
            LATIN_1 = "latin-1"
            ISO_8859_1 = "iso-8859-1"

    # =========================================================================
    # Server identification - accessed via Constants via properties in base.py
    # =========================================================================
    # NOTE: server_type and priority are accessed via properties in base.py
    # which read from Constants.SERVER_TYPE and Constants.PRIORITY

    # === PUBLIC INTERFACE FOR SCHEMA CONFIGURATION ===

    @classmethod
    def get_schema_filterable_fields(cls) -> frozenset[str]:
        """Get schema fields that support OID filtering.

        Returns:
            frozenset of schema field names (attributetypes, objectclasses, etc.)

        """
        return cls.Constants.SCHEMA_FILTERABLE_FIELDS

    @classmethod
    def get_schema_dn(cls) -> str:
        """Get the target schema DN for this server.

        Returns:
            Schema DN in OUD format (cn=schema)

        """
        return cls.Constants.SCHEMA_DN

    # =========================================================================
    # SHARED HELPER METHODS - Used by both Schema and Entry nested classes
    # =========================================================================

    @staticmethod
    def _add_ldif_block_static(
        ldif_lines: list[str],
        schema_type: str,
        value: str | bytes,
        *,
        is_first_block: bool,
    ) -> bool:
        """Add a single LDIF block for schema value - static helper.

        Args:
            ldif_lines: List to append LDIF lines to
            schema_type: Schema type (attributeTypes, objectClasses, etc.)
            value: Schema value (string or bytes)
            is_first_block: Whether this is the first block

        Returns:
            False (next block won't be first)

        """
        # Add separator before block (not before first)
        if not is_first_block:
            ldif_lines.append("-")

        # Add directive
        ldif_lines.append(f"add: {schema_type}")

        # Value (already in RFC format)
        if isinstance(value, bytes):
            encoded_value = base64.b64encode(value).decode("ascii")
            ldif_lines.append(f"{schema_type}:: {encoded_value}")
        else:
            ldif_lines.append(f"{schema_type}: {value}")

        return False  # Next block won't be first

    class Schema(FlextLdifServersRfc.Schema):
        """Oracle OUD schema quirk - implements FlextLdifProtocols.Quirks.SchemaProtocol.

        Extends RFC 4512 schema parsing with Oracle OUD-specific features:
        - OUD namespace (2.16.840.1.113894.*)
        - OUD-specific syntaxes
        - OUD attribute extensions
        - Compatibility with vendor-specific schemas
        - DN case registry management for schema consistency

        **Protocol Compliance**: Fully implements
        FlextLdifProtocols.Quirks.SchemaProtocol through structural typing.
        All methods match protocol signatures exactly for type safety.

        **Validation**: Verify protocol compliance with:
            from flext_ldif.protocols import FlextLdifProtocols
            quirk = FlextLdifServersOud()
            # Protocol compliance verified via structural typing
            if not isinstance(quirk, FlextLdifProtocols.Quirks.SchemaProtocol):
                raise TypeError("Quirk does not satisfy SchemaProtocol")

        Example:
            quirk = FlextLdifServersOud()
            if quirk.schema.can_handle_attribute(attr_def):
                result = quirk.schema.parse(attr_def)
                if result.is_success:
                    parsed_attr = result.unwrap()

        """

        def __init__(
            self,
            schema_service: object | None = None,
            **kwargs: object,
        ) -> None:
            """Initialize OUD schema quirk.

            OUD extends RFC baseline with Oracle-specific enhancements.

            Args:
                schema_service: Injected FlextLdifSchema service (optional)
                **kwargs: Passed to parent for compatibility

            """
            super().__init__(schema_service=schema_service, **kwargs)

        def _hook_post_parse_attribute(
            self,
            attr: FlextLdifModels.SchemaAttribute,
        ) -> FlextResult[FlextLdifModels.SchemaAttribute]:
            """Hook: Validate OUD-specific attribute features after parsing.

            OUD supports extensions beyond RFC 4512:
            - Non-numeric OIDs: ending with `-oid` suffix (e.g., `1.2.3-oid`)
            - X-* extensions: X-PATTERN, X-ENUM, X-SUBST, X-APPROX,
              X-ORIGIN, X-SCHEMA-FILE
            - DN normalization for distinguishedName syntax attributes

            Validation rules (fail if violated):
            1. OIDs must be numeric or end with `-oid` suffix
            2. X-* extensions must be well-formed
            3. SYNTAX must reference valid OID

            Args:
                attr: Parsed SchemaAttribute from RFC parser

            Returns:
                FlextResult[SchemaAttribute] - validated and metadata-enriched attribute

            """
            if not attr or not attr.oid:
                return FlextResult[FlextLdifModels.SchemaAttribute].ok(attr)

            oid = str(attr.oid)

            # Validate OID format: numeric or ending in -oid (OUD extension)
            if not oid.replace(".", "").replace("-", "").isalnum():
                return FlextResult[FlextLdifModels.SchemaAttribute].fail(
                    f"Invalid OUD OID format: {oid} (must be numeric or end with -oid)",
                )

            # Log if OUD-specific X-* extensions detected
            oud_extensions = []
            if attr.x_origin:
                oud_extensions.append("X-ORIGIN")
            if attr.x_file_ref:
                oud_extensions.append("X-FILE-REF")
            if attr.x_name:
                oud_extensions.append("X-NAME")
            if attr.x_alias:
                oud_extensions.append("X-ALIAS")
            if attr.x_oid:
                oud_extensions.append("X-OID")

            if oud_extensions:
                logger.debug(
                    "Attribute has OUD X-* extensions",
                    attribute_name=attr.name,
                    attribute_oid=attr.oid,
                    extensions=oud_extensions,
                    extension_count=len(oud_extensions),
                )

            return FlextResult[FlextLdifModels.SchemaAttribute].ok(attr)

        def _hook_post_parse_objectclass(
            self,
            oc: FlextLdifModels.SchemaObjectClass,
        ) -> FlextResult[FlextLdifModels.SchemaObjectClass]:
            """Hook: Validate OUD-specific objectClass features after parsing.

            OUD has specific constraints different from RFC:
            - SingleSUP: Only ONE superior class allowed (RFC allows
              multiple via $)
            - X-* extensions: X-ENUM, X-PATTERN, X-ORIGIN, X-SCHEMA-FILE
            - No multiple structural chains (enforced separately by config)

            Validation rules (fail if violated):
            1. SUP must be single (not multiple separated by $)
            2. X-* extensions must be well-formed
            3. MUST/MAY attributes must exist in schema (done in
               validate_objectclass_dependencies)

            Args:
                oc: Parsed SchemaObjectClass from RFC parser

            Returns:
                FlextResult[SchemaObjectClass] - validated objectClass

            """
            if not oc:
                return FlextResult[FlextLdifModels.SchemaObjectClass].fail(
                    "ObjectClass is None or empty",
                )

            # Validate SingleSUP constraint (OUD restriction)
            sup = oc.sup
            if sup:
                sup_str = str(sup)
                # Check for multiple SUPs (RFC uses $ as separator)
                if "$" in sup_str:
                    return FlextResult[FlextLdifModels.SchemaObjectClass].fail(
                        f"OUD objectClass '{oc.name}' has multiple SUPs: "
                        f"{sup_str}. "
                        "OUD only allows single SUP (use AUXILIARY classes "
                        "for additional features).",
                    )

            # ObjectClass doesn't have X-* extension fields in model
            # Log just the validation success
            logger.debug(
                "ObjectClass validated: SingleSUP constraint OK",
                objectclass_name=oc.name,
                objectclass_oid=oc.oid,
                sup_value=oc.sup,
            )

            return FlextResult[FlextLdifModels.SchemaObjectClass].ok(oc)

        def _build_source_rules(
            self,
            validated_attr: FlextLdifModels.SchemaAttribute,
        ) -> dict[str, str]:
            """Build source matching rules dict."""
            source_rules = {}
            if validated_attr.equality:
                source_rules["equality"] = validated_attr.equality
            if validated_attr.substr:
                source_rules["substr"] = validated_attr.substr
            if validated_attr.ordering:
                source_rules["ordering"] = validated_attr.ordering
            return source_rules

        def _add_metadata_context(
            self,
            validated_attr: FlextLdifModels.SchemaAttribute,
            meta_keys: type[FlextLdifConstants.MetadataKeys],
            context: str = "source",
            attr_definition: str | None = None,
            source_rules: dict[str, str] | None = None,
        ) -> None:
            """Add metadata fields for given context (source or target).

            Args:
                validated_attr: Attribute to add metadata to
                meta_keys: Metadata keys constant class
                context: "source" or "target" - determines which keys to use
                attr_definition: Original definition string (source context only)
                source_rules: Matching rules dict (target context only)

            """
            # Ensure metadata exists
            if not validated_attr.metadata:
                validated_attr.metadata = FlextLdifModels.QuirkMetadata(
                    quirk_type="oud",
                    extensions={},
                )
            if not validated_attr.metadata.extensions:
                validated_attr.metadata.extensions = {}

            # Source context: preserve original format and formatting
            if context == "source" and attr_definition:
                validated_attr.metadata.extensions[meta_keys.SCHEMA_ORIGINAL_FORMAT] = (
                    attr_definition.strip()
                )
                validated_attr.metadata.extensions[
                    meta_keys.SCHEMA_ORIGINAL_STRING_COMPLETE
                ] = attr_definition
                validated_attr.metadata.extensions[meta_keys.SCHEMA_SOURCE_SERVER] = "oud"

                # Preserve schema formatting details
                if not isinstance(validated_attr.metadata, FlextLdifModels.QuirkMetadata):
                    metadata_public = FlextLdifModels.QuirkMetadata.model_validate(
                        validated_attr.metadata.model_dump(),
                    )
                else:
                    metadata_public = validated_attr.metadata
                FlextLdifUtilities.Metadata.preserve_schema_formatting(
                    metadata_public,
                    attr_definition,
                )

            # Add syntax and name for both contexts (OUD: source == target)
            syntax_key = (
                meta_keys.SCHEMA_SOURCE_SYNTAX_OID
                if context == "source"
                else meta_keys.SCHEMA_TARGET_SYNTAX_OID
            )
            name_key = (
                meta_keys.SCHEMA_SOURCE_ATTRIBUTE_NAME
                if context == "source"
                else meta_keys.SCHEMA_TARGET_ATTRIBUTE_NAME
            )

            if validated_attr.syntax:
                validated_attr.metadata.extensions[syntax_key] = str(
                    validated_attr.syntax
                )
            if validated_attr.name:
                validated_attr.metadata.extensions[name_key] = validated_attr.name

            # Target context: add matching rules
            if context == "target" and source_rules:
                validated_attr.metadata.extensions[
                    meta_keys.SCHEMA_TARGET_MATCHING_RULES
                ] = source_rules

        def validate_objectclass_dependencies(
            self,
            oc_data: FlextLdifModels.SchemaObjectClass,
            available_attributes: set[str],
        ) -> FlextResult[bool]:
            """Validate objectclass attribute dependencies via utility.

            Args:
                oc_data: Parsed objectclass Pydantic model
                available_attributes: Set of available attribute names

            Returns:
                FlextResult[bool]: True if valid, False if missing attributes

            """
            if not oc_data.name:
                return FlextResult[bool].fail("ObjectClass name is required")
            if not oc_data.oid:
                return FlextResult[bool].fail("ObjectClass OID is required")

            is_valid, missing = FlextLdifUtilities.Schema.validate_objectclass_dependencies(
                str(oc_data.name),
                str(oc_data.oid),
                oc_data.must,
                oc_data.may,
                available_attributes,
            )

            if not is_valid and missing:
                logger.warning(
                    "ObjectClass has unresolved attributes - filtered out",
                    objectclass_name=oc_data.name,
                    missing_attributes=missing,
                )

            return FlextResult[bool].ok(is_valid)

        def _transform_attribute_for_write(
            self,
            attr_data: FlextLdifModels.SchemaAttribute,
        ) -> FlextLdifModels.SchemaAttribute:
            """Apply OUD-specific attribute transformations before writing.

            Implements hook from RFC base to apply OUD quirks:
            - Validate matching rules are RFC-compliant
            - Correct invalid SUBSTR rules
            - Track boolean attributes for special handling
            - Preserve OUD-specific extensions

            Args:
                attr_data: Parsed SchemaAttribute model

            Returns:
                Transformed SchemaAttribute with OUD-specific fixes applied

            """
            # Normalize name if present
            fixed_name = attr_data.name

            # Validate and enhance matching rules for OUD compatibility
            fixed_equality = attr_data.equality
            fixed_substr = attr_data.substr

            # OUD QUIRK: caseIgnoreSubstringsMatch must be SUBSTR, not EQUALITY
            # If equality is caseIgnoreSubstringsMatch, move it to substr
            if fixed_equality == "caseIgnoreSubstringsMatch":
                logger.warning(
                    "Moved caseIgnoreSubstringsMatch from EQUALITY to SUBSTR",
                    attribute_name=attr_data.name,
                )
                fixed_substr = "caseIgnoreSubstringsMatch"
                fixed_equality = None  # Remove from equality - must be explicitly None, not empty string

            # OUD QUIRK: Remove redundant EQUALITY when SUBSTR is caseIgnoreSubstringsMatch
            # OUD rejects: EQUALITY caseIgnoreMatch SUBSTR caseIgnoreSubstringsMatch
            # OUD accepts: SUBSTR caseIgnoreSubstringsMatch (EQUALITY removed)
            # This affects 135 attributes exported by OID with redundant matching rules
            if (
                fixed_substr == "caseIgnoreSubstringsMatch"
                and fixed_equality == "caseIgnoreMatch"
            ):
                logger.warning(
                    "OUD QUIRK: FOUND REDUNDANT EQUALITY+SUBSTR - Removing redundant EQUALITY",
                    attribute_name=fixed_name,
                    attribute_oid=attr_data.oid,
                    # Before/After comparison
                    original_equality=fixed_equality,
                    original_substr=fixed_substr,
                    new_equality=None,
                    new_substr="caseIgnoreSubstringsMatch",
                    redundant_equality="caseIgnoreMatch",
                )
                fixed_equality = None  # Remove redundant EQUALITY

            # Check for invalid SUBSTR rules and apply INVALID_SUBSTR_RULES mappings
            invalid_substr_rules = FlextLdifServersOud.Constants.INVALID_SUBSTR_RULES
            if fixed_substr and fixed_substr in invalid_substr_rules:
                replacement = invalid_substr_rules[fixed_substr]
                if replacement is not None:
                    logger.warning(
                        "Replacing invalid SUBSTR rule",
                        attribute_name=attr_data.name,
                        attribute_oid=attr_data.oid,
                        # Before/After comparison
                        original_substr=fixed_substr,
                        replacement_substr=replacement,
                        equality_rule=fixed_equality,
                        replacement_mapping=invalid_substr_rules.get(fixed_substr),
                    )
                    fixed_substr = replacement

            # Check if this is a boolean attribute for special handling during write
            is_boolean = FlextLdifUtilities.Schema.is_boolean_attribute(
                fixed_name,
                set(FlextLdifServersOud.Constants.BOOLEAN_ATTRIBUTES),
            )
            if is_boolean:
                logger.debug(
                    "Identified boolean attribute",
                    attribute_name=fixed_name,
                    attribute_oid=attr_data.oid,
                    original_name=attr_data.name
                    if attr_data.name != fixed_name
                    else None,
                )

            # Create modified copy with fixed values using Pydantic v2 pattern
            return attr_data.model_copy(
                update={
                    "name": fixed_name,
                    "equality": fixed_equality,
                    "substr": fixed_substr,
                },
            )

        def extract_schemas_from_ldif(
            self,
            ldif_content: str,
            *,
            validate_dependencies: bool = True,  # OUD defaults to True (needs validation)
        ) -> FlextResult[dict[str, object]]:
            """Extract and parse all schema definitions from LDIF content.

            OUD-specific implementation: Uses base template method with dependency
            validation enabled by default. The template method handles attribute
            extraction, available_attributes set building, and objectClass extraction.

            Strategy pattern: OUD requires dependency validation to ensure all
            attributes referenced in objectClass MUST/MAY lists are available.

            Filters only Oracle internal objectClasses that OUD already provides built-in.
            All custom objectClasses pass through, including those with unresolved
            dependencies (OUD will validate at startup).

            Args:
                ldif_content: Raw LDIF content containing schema definitions
                validate_dependencies: Enable dependency validation (default: True for OUD)

            Returns:
                FlextResult with dict containing schema data
                (ATTRIBUTES and objectclasses lists)

            """
            # Use base template method with OUD's dependency validation
            # This replaces 66 lines of duplicated code with a 3-line call
            return super().extract_schemas_from_ldif(
                ldif_content,
                validate_dependencies=validate_dependencies,
            )

        @staticmethod
        def clean_syntax_quotes(value: str | bytes) -> str | bytes:
            """OUD QUIRK: Remove quotes from SYNTAX OID in schema definitions.

            RFC 4512 § 4.1.2: SYNTAX OID must NOT be quoted.
            OID server exports: SYNTAX '1.3.6.1.4.1.1466.115.121.1.7' (invalid)
            OUD requires: SYNTAX 1.3.6.1.4.1.1466.115.121.1.7 (valid)

            Args:
                value: Schema definition string (attributeTypes, objectClasses)

            Returns:
                Cleaned value with quotes removed from SYNTAX OID

            """
            if isinstance(value, bytes):
                return value  # Binary values don't need cleaning

            # Pattern: SYNTAX followed by optional space, quotes, OID, quotes
            # Captures: SYNTAX '1.3.6.1.4.1.1466.115.121.1.7' or SYNTAX "..."
            syntax_pattern = re.compile(r"SYNTAX\s+['\"]([0-9.]+)['\"]")

            # Replace quoted SYNTAX OID with unquoted version
            return syntax_pattern.sub(r"SYNTAX \1", value)

    class Acl(FlextLdifServersRfc.Acl):
        """Oracle OUD ACL quirk (nested).

        Extends RFC ACL parsing with Oracle OUD-specific ACL formats:
        - ds-cfg-access-control-handler: OUD access control
        - OUD-specific ACL syntax (RFC-compliant ACI format)

        Example:
            quirk = FlextLdifServersOud.Acl()
            if quirk.can_handle(acl_line):
                result = quirk.parse(acl_line)

        """

        # =====================================================================
        # PROTOCOL IMPLEMENTATION: FlextLdifProtocols.ServerAclProtocol
        # =====================================================================

        # RFC Foundation - Standard LDAP attributes (all servers start here)
        RFC_ACL_ATTRIBUTES: ClassVar[list[str]] = [
            "aci",  # Standard LDAP (RFC 4876)
            "acl",  # Alternative format
            "olcAccess",  # OpenLDAP
            "aclRights",  # Generic rights
            "aclEntry",  # ACL entry
        ]

        # OUD-specific ACL extensions
        # Oracle ACI compatibility (alternative ACL format support)
        OUD_ACL_ATTRIBUTES: ClassVar[list[str]] = [
            "ds-privilege-name",  # OUD privilege system - native OUD attribute
        ]

        def get_acl_attributes(self) -> list[str]:
            """Get RFC + OUD extensions.

            Returns:
                List of ACL attribute names (RFC foundation + OUD-specific)

            """
            return self.RFC_ACL_ATTRIBUTES + self.OUD_ACL_ATTRIBUTES

        # is_acl_attribute inherited from base class (uses set for O(1) lookup)

        # OVERRIDDEN METHODS (from FlextLdifServersBase.Acl)
        # These methods override the base class with Oracle OUD-specific logic:
        # - can_handle(): Detects OUD ACL formats
        # - parse(): Normalizes Oracle OUD ACL to RFC-compliant internal model
        # - write(): Serializes RFC-compliant model to OUD ACI format
        # - get_attribute_name(): Returns "aci" (OUD-specific, overridden)

        # Oracle OUD server configuration defaults

        def __init__(
            self,
            acl_service: object | None = None,
            **kwargs: object,
        ) -> None:
            """Initialize OUD ACL quirk.

            Args:
                acl_service: Injected FlextLdifAcl service (optional)
                **kwargs: Passed to parent for compatibility

            """
            super().__init__(acl_service=acl_service, **kwargs)
            # NOTE: Hook registration was removed - AclConverter was moved to services/acl.py
            # Use FlextLdifAcl instead for ACL conversion operations

        # NOTE: Obsolete method removed - hook registration pattern changed
        # AclConverter was moved to services/acl.py as FlextLdifAcl
        # Use FlextLdifAcl for ACL format conversions (RFC → server-specific format)

        def can_handle(self, acl_line: FlextLdifTypes.AclOrString) -> bool:
            """Check if this is an Oracle OUD ACL (public method).

            Args:
                acl_line: ACL line string or Acl model to check.

            Returns:
                True if this is Oracle OUD ACL format

            """
            return self.can_handle_acl(acl_line)

        def can_handle_acl(self, acl_line: FlextLdifTypes.AclOrString) -> bool:
            """Check if this is an Oracle OUD ACL line (implements abstract method from base.py).

            Detects Oracle OUD ACL by checking if the line starts with:
            - "aci:" (RFC 4876 compliant ACI)
            - "targetattr=" (inline ACI format)
            - "targetscope=" (inline ACI format)
            - "version 3.0" (ACI version marker)
            - "ds-cfg-" (OUD configuration ACL)

            Args:
                acl_line: Raw ACL line string or Acl model from LDIF

            Returns:
                True if this is Oracle OUD ACL format

            """
            # Handle Acl model: check metadata quirk type or attribute name
            if isinstance(acl_line, FlextLdifModels.Acl):
                if acl_line.metadata and acl_line.metadata.quirk_type:
                    return str(acl_line.metadata.quirk_type) == self._get_server_type()
                return (
                    bool(acl_line.name)
                    and (
                        FlextLdifUtilities.Schema.normalize_attribute_name(acl_line.name)
                        == FlextLdifUtilities.Schema.normalize_attribute_name(
                            FlextLdifServersOud.Constants.ACL_ATTRIBUTE_NAME,
                        )
                    )
                    if acl_line.name
                    else False
                )

            # Handle string: empty string check
            if not acl_line or not (normalized := acl_line.strip()):
                return False

            # Check for OUD ACL patterns using constants
            normalized_lower = normalized.lower()
            oud_prefixes = (
                FlextLdifServersOud.Constants.ACL_ACI_PREFIX,
                FlextLdifServersOud.Constants.ACL_TARGETATTR_PREFIX,
                FlextLdifServersOud.Constants.ACL_TARGETSCOPE_PREFIX,
                FlextLdifServersOud.Constants.ACL_DEFAULT_VERSION,
            )

            # RFC 4876 ACI format OR OUD config ACL
            if normalized.startswith(oud_prefixes) or "ds-cfg-" in normalized_lower:
                return True

            # ds-privilege-name format: simple privilege names without prohibited patterns
            return not any(
                pattern in normalized_lower
                for pattern in ["access to", "(", ")", "=", ":"]
            )

        def _parse_acl(self, acl_line: str) -> FlextResult[FlextLdifModels.Acl]:
            """Parse Oracle OUD ACL string to RFC-compliant internal model.

            Supports two OUD native ACL formats:
            1. RFC 4876 ACI format: aci: (targetattr=...)(version 3.0; acl "name"; ...)
            2. ds-privilege-name format: Simple privilege names like "config-read", "password-reset"

            Note: OUD does NOT parse Oracle Internet Directory (OID) formats directly.
            If receiving OID data, it must be pre-converted via RFC Entry Model first.

            Args:
            acl_line: ACL definition line (may be ACI, alternative format, or ds-privilege-name)

            Returns:
            FlextResult with OUD ACL Pydantic model

            """
            # Type guard: ensure acl_line is a string
            if not isinstance(acl_line, str):
                return FlextResult[FlextLdifModels.Acl].fail(
                    f"ACL line must be a string, got {type(acl_line).__name__}",
                )
            normalized = acl_line.strip()

            # Detect format: RFC 4876 ACI or ds-privilege-name
            # OUD ONLY handles OUD-native formats - Alternative format data comes pre-converted via RFC Entry Model
            if normalized.startswith(FlextLdifServersOud.Constants.ACL_ACI_PREFIX):
                # RFC 4876 ACI format (OUD native format)
                return self._parse_aci_format(acl_line)

            # Try RFC parser first for other non-ACI formats
            # This handles cases where RFC Entry Model data needs to be parsed
            rfc_result = super()._parse_acl(acl_line)
            if rfc_result.is_success:
                # RFC parser succeeded - check if it has a valid name
                # If name is empty and line doesn't look like RFC format, try ds-privilege-name
                acl_model = rfc_result.unwrap()
                if acl_model.name or normalized.startswith("aci:"):
                    # RFC parser returned valid result with name or recognized format
                    return rfc_result

            # If RFC parser fails or returned empty name, try ds-privilege-name format
            # OUD-specific simple privilege names (config-read, password-reset, etc.)
            return self._parse_ds_privilege_name(normalized)

        def _parse_aci_format(self, acl_line: str) -> FlextResult[FlextLdifModels.Acl]:
            """Parse RFC 4876 ACI format using utility with OUD config.

            Uses FlextLdifUtilitiesACL.parse_aci with OUD-specific AciParserConfig.
            Config includes all OUD patterns, permission maps, and special subjects.

            Args:
                acl_line: ACL definition line with 'aci:' prefix

            Returns:
                FlextResult with OUD ACL Pydantic model

            """
            config = FlextLdifServersOud.Constants.get_parser_config()
            result = FlextLdifUtilities.ACL.parse_aci(acl_line, config)

            if not result.is_success:
                return result

            # Post-process for OUD-specific multi-group patterns (timeofday, ssf)
            acl = result.unwrap()
            aci_content = acl_line.split(":", 1)[1].strip() if ":" in acl_line else ""
            extensions = dict(acl.metadata.extensions) if acl.metadata else {}

            # Handle bind_timeofday (captures operator + value)
            timeofday_match = re.search(
                FlextLdifServersOud.Constants.ACL_TIMEOFDAY_PATTERN,
                aci_content,
            )
            if timeofday_match:
                extensions["bind_timeofday"] = (
                    f"{timeofday_match.group(1)}{timeofday_match.group(2)}"
                )

            # Handle SSF (captures operator + value)
            ssf_match = re.search(
                FlextLdifServersOud.Constants.ACL_SSF_PATTERN,
                aci_content,
            )
            if ssf_match:
                extensions["ssf"] = f"{ssf_match.group(1)}{ssf_match.group(2)}"

            # Update metadata if extensions changed
            if extensions != (acl.metadata.extensions if acl.metadata else {}):
                new_metadata = FlextLdifModels.QuirkMetadata.create_for(
                    config.server_type,
                    extensions=extensions,
                )
                acl = acl.model_copy(update={"metadata": new_metadata})

            return FlextResult[FlextLdifModels.Acl].ok(acl)

        def _parse_ds_privilege_name(
            self,
            privilege_name: str,
        ) -> FlextResult[FlextLdifModels.Acl]:
            """Parse OUD ds-privilege-name format (simple privilege names).

            Oracle OUD uses simple privilege names for access control:
            - config-read, config-write, config-delete
            - password-reset, password-change
            - bypass-acl, bypass-lockdown
            - And other administrative privileges

            Args:
            privilege_name: Simple privilege name (e.g., "config-read")

            Returns:
            FlextResult with OUD ACL Pydantic model

            """
            try:
                # Build minimal ACL model for ds-privilege-name
                # This format doesn't have traditional target/subject/permissions
                acl_model = FlextLdifModels.Acl(
                    name=privilege_name,  # Use privilege name as ACL name
                    target=None,  # No target in ds-privilege-name format
                    subject=None,  # No subject in ds-privilege-name format
                    permissions=None,  # No traditional read/write/add permissions
                    server_type=FlextLdifServersOud.Constants.SERVER_TYPE,  # OUD server type from Constants
                    raw_line=privilege_name,  # Original line
                    raw_acl=privilege_name,  # Raw ACL string
                    validation_violations=[],  # No validation issues
                    metadata=FlextLdifModels.QuirkMetadata(
                        quirk_type=FlextLdifServersOud.Constants.SERVER_TYPE,  # OUD quirk type from Constants
                        extensions={
                            "ds_privilege_name": privilege_name,
                            "format_type": "ds-privilege-name",
                        },
                    ),
                )

                return FlextResult[FlextLdifModels.Acl].ok(acl_model)

            except Exception as e:
                logger.exception(
                    "Failed to parse OUD ds-privilege-name",
                )
                return FlextResult[FlextLdifModels.Acl].fail(
                    f"Failed to parse OUD ds-privilege-name: {e}",
                )

        # ===== _create_acl_from_context HELPER METHODS (DRY refactoring) =====

        def _build_oud_permissions(
            self,
            permissions_list: list[str],
        ) -> dict[str, bool]:
            """Build OUD permissions dictionary with 'all' handling.

            Args:
                permissions_list: List of permission strings

            Returns:
                Permissions dict with bool values

            """
            perm_map = {
                "read": FlextLdifServersOud.Constants.PERMISSION_READ,
                "write": FlextLdifServersOud.Constants.PERMISSION_WRITE,
                "add": FlextLdifServersOud.Constants.PERMISSION_ADD,
                "delete": FlextLdifServersOud.Constants.PERMISSION_DELETE,
                "search": FlextLdifServersOud.Constants.PERMISSION_SEARCH,
                "compare": FlextLdifServersOud.Constants.PERMISSION_COMPARE,
                "selfwrite": FlextLdifServersOud.Constants.PERMISSION_SELF_WRITE,
                "self_write": FlextLdifServersOud.Constants.PERMISSION_SELF_WRITE,
                "proxy": FlextLdifServersOud.Constants.PERMISSION_PROXY,
            }
            raw_perms = FlextLdifUtilities.ACL.build_permissions_dict(
                permissions_list,
                perm_map,
            )

            # Handle "all" permission special case - set all to True
            if FlextLdifUtilities.Schema.is_attribute_in_list(
                FlextLdifServersOud.Constants.PERMISSION_ALL,
                permissions_list,
            ):
                return dict.fromkeys(raw_perms, True)

            # Convert object values to bool
            return {k: bool(v) for k, v in raw_perms.items()}

        def _build_oud_subject(
            self,
            bind_rules_data: list[dict[str, str]],
        ) -> tuple[str, str]:
            """Build OUD ACL subject from bind rules.

            Args:
                bind_rules_data: List of bind rule dicts with 'type' and 'value' keys
                    (matches extract_bind_rules return type)

            Returns:
                Tuple of (subject_type, subject_value)

            """
            subject_type_map = {
                FlextLdifServersOud.Constants.ACL_BIND_RULE_TYPE_USERDN: FlextLdifServersOud.Constants.ACL_SUBJECT_TYPE_BIND_RULES,
                FlextLdifServersOud.Constants.ACL_BIND_RULE_TYPE_GROUPDN: "group",
            }
            special_values = {
                FlextLdifServersOud.Constants.ACL_SELF_SUBJECT: (
                    "self",
                    FlextLdifServersOud.Constants.ACL_SELF_SUBJECT,
                ),
                "self": ("self", FlextLdifServersOud.Constants.ACL_SELF_SUBJECT),
                FlextLdifServersOud.Constants.ACL_ANONYMOUS_SUBJECT: ("anonymous", "*"),
                "anyone": ("anonymous", "*"),
                FlextLdifServersOud.Constants.ACL_ANONYMOUS_SUBJECT_ALT: (
                    "anonymous",
                    "*",
                ),
                "*": ("anonymous", "*"),
            }
            return FlextLdifUtilities.ACL.build_acl_subject(
                bind_rules_data,
                subject_type_map,
                special_values,
            )

        def _parse_targetattr(
            self,
            targetattr_str: str,
        ) -> tuple[list[str], str]:
            """Parse targetattr string to attributes list and target DN.

            Args:
                targetattr_str: Target attribute string

            Returns:
                Tuple of (target_attributes, target_dn)

            """
            if targetattr_str and "||" in targetattr_str:
                # Multiple attributes: "cn || sn || mail" -> ["cn", "sn", "mail"]
                target_attributes = [
                    attr.strip() for attr in targetattr_str.split("||") if attr.strip()
                ]
                return target_attributes, "*"
            if targetattr_str and targetattr_str != "*":
                # Single attribute
                return [targetattr_str.strip()], "*"
            # Wildcard
            return [], "*"

        def _should_use_raw_acl(self, acl_data: FlextLdifModels.Acl) -> bool:
            """Check if raw_acl should be used as-is.

            Args:
                acl_data: ACL model instance

            Returns:
                True if raw_acl should be used (only if already in proper OUD format)

            """
            if not acl_data.raw_acl:
                return False

            # Use raw_acl ONLY if already in OUD format (aci: prefix)
            # All other formats (OID, etc.) must be converted
            return acl_data.raw_acl.startswith(
                FlextLdifServersOud.Constants.ACL_ACI_PREFIX,
            )

        def _build_aci_target(self, acl_data: FlextLdifModels.Acl) -> str:
            """Build ACI target attributes part using utility (CONSOLIDATED)."""
            # Extract target from model or metadata
            target = acl_data.target
            if not target and acl_data.metadata:
                target_dict = acl_data.metadata.extensions.get("acl_target_target")
                if FlextRuntime.is_dict_like(target_dict):
                    target_data: dict[str, object] = dict(target_dict)
                    attrs = target_data.get("attributes")
                    dn = target_data.get("target_dn")
                    target = FlextLdifModels.AclTarget(
                        target_dn=str(dn) if isinstance(dn, str) else "*",
                        attributes=list(attrs) if isinstance(attrs, list) else [],
                    )

            # CONSOLIDATED: Use utility for formatting
            return FlextLdifUtilities.ACL.build_aci_target_clause(
                target_attributes=target.attributes if target else None,
                target_dn=target.target_dn if target else None,
                separator=" || ",
            )

        def _build_aci_permissions(
            self,
            acl_data: FlextLdifModels.Acl,
        ) -> FlextResult[str]:
            """Build ACI permissions part.

            Args:
                acl_data: ACL model instance

            Returns:
                FlextResult with formatted permissions string

            """
            # Get permissions from model field or metadata
            perms = acl_data.permissions

            if not perms and acl_data.metadata:
                # Reconstruct permissions from ACL_TARGET_PERMISSIONS metadata
                # This is set during conversion from source server (e.g., OID→OUD)
                target_perms_dict = acl_data.metadata.extensions.get(
                    FlextLdifConstants.MetadataKeys.ACL_TARGET_PERMISSIONS,
                )
                if FlextRuntime.is_dict_like(target_perms_dict):
                    # Type narrowing: ensure dict has correct types
                    perms_data: dict[str, object] = dict(target_perms_dict)
                    # Extract boolean fields with type guards - only use fields that exist in AclPermissions
                    perms = FlextLdifModels.AclPermissions(
                        read=bool(perms_data.get("read")),
                        write=bool(perms_data.get("write")),
                        add=bool(perms_data.get("add")),
                        delete=bool(perms_data.get("delete")),
                        search=bool(perms_data.get("search")),
                        compare=bool(perms_data.get("compare")),
                        self_write=bool(
                            perms_data.get("self_write") or perms_data.get("selfwrite"),
                        ),
                        proxy=bool(perms_data.get("proxy")),
                    )

            if not perms:
                return FlextResult[str].fail("ACL model has no permissions object")

            # Extract permission names from boolean fields directly
            ops: list[str] = [
                field_name
                for field_name in (
                    "read",
                    "write",
                    "add",
                    "delete",
                    "search",
                    "compare",
                    "self_write",
                    "proxy",
                )
                if getattr(perms, field_name, False)
            ]

            # Filter to only OUD-supported rights using utility
            filtered_ops = FlextLdifUtilities.ACL.filter_supported_permissions(
                ops,
                FlextLdifServersOud.Constants.SUPPORTED_PERMISSIONS,
            )

            # Check metadata bridge for self_write promotion
            if (
                acl_data.metadata
                and acl_data.metadata.extensions.get("self_write_to_write")
                and FlextLdifServersOud.Constants.PERMISSION_SELF_WRITE in ops
                and "write" not in filtered_ops
            ):
                filtered_ops.append("write")

            if not filtered_ops:
                return FlextResult[str].fail(
                    f"ACL model has no OUD-supported permissions (all were unsupported vendor-specific permissions like {FlextLdifServersOud.Constants.PERMISSION_SELF_WRITE}, stored in metadata)",
                )

            ops_str = ",".join(filtered_ops)
            return FlextResult[str].ok(
                f"{FlextLdifServersOud.Constants.ACL_ALLOW_PREFIX}{ops_str})",
            )

        def _extract_and_resolve_acl_subject(
            self,
            acl_data: FlextLdifModels.Acl,
        ) -> tuple[str | None, str, str]:
            """Extract metadata and resolve subject type and value in one pass.

            Returns:
                Tuple of (base_dn, subject_type_for_format, subject_value_str)

            """
            # Extract metadata with type guards in compact form
            ext = (
                acl_data.metadata.extensions
                if acl_data.metadata and hasattr(acl_data.metadata, "extensions")
                else None
            )
            base_dn = (
                base_dn_val if isinstance(base_dn_val := ext.get("base_dn"), str)
                else None
            ) if ext else None
            source_subject_type = (
                sst if isinstance(sst := ext.get(MetaKeys.ACL_SOURCE_SUBJECT_TYPE), str)
                else None
            ) if ext else None

            # Determine subject type using single pass logic
            subject_type = (
                acl_data.subject.subject_type
                if acl_data.subject
                else source_subject_type
            ) or "self"

            # Map bind_rules to actual subject type using metadata
            if subject_type == "bind_rules":
                if source_subject_type in {"dn_attr", "guid_attr", "group_attr"}:
                    subject_type = source_subject_type
                elif source_subject_type == "group_dn" or (
                    acl_data.subject
                    and acl_data.subject.subject_value
                    and any(
                        kw in acl_data.subject.subject_value.lower()
                        for kw in ("group=", "groupdn")
                    )
                ):
                    subject_type = "group"

            # Resolve subject value with metadata fallback
            subject_value = (
                acl_data.subject.subject_value if acl_data.subject else None
            ) or (
                sv
                if ext and isinstance(sv := ext.get(MetaKeys.ORIGINAL_SUBJECT_VALUE), str)
                else None
            )

            # Default self values
            if not subject_value and subject_type == "self":
                subject_value = FlextLdifServersOud.Constants.ACL_SELF_SUBJECT
            if not subject_value:
                subject_value = ""

            return base_dn, subject_type, subject_value

        def _build_aci_subject(self, acl_data: FlextLdifModels.Acl) -> str:
            """Build ACI bind rules (subject) part using consolidated extraction."""
            # Extract and resolve in one pass
            base_dn, subject_type, subject_value = self._extract_and_resolve_acl_subject(
                acl_data
            )

            # Default to self if no subject type
            if not subject_type or subject_type == "self":
                return f'userdn="{FlextLdifServersOud.Constants.ACL_SELF_SUBJECT}";)'

            # Filter base_dn from subject value if present
            filtered_value = (
                subject_value[: -len(base_dn)].rstrip(",")
                if (base_dn and subject_value.endswith(base_dn))
                else subject_value
            )

            # Map subject type to bind operator and format
            bind_operator = {"user": "userdn", "group": "groupdn", "role": "roledn"}.get(
                subject_type, "userdn"
            )
            return FlextLdifUtilities.ACL.format_aci_subject(
                subject_type, filtered_value, bind_operator
            )

        def write(self, acl_data: FlextLdifModels.Acl) -> FlextResult[str]:
            """Write RFC-compliant ACL model to OUD ACI string format.

            Serializes the RFC-compliant internal model to Oracle OUD ACI format string,
            including comprehensive comment generation for vendor-specific ACL format conversions
            to ensure zero data loss (all unsupported features tracked in metadata).

            Args:
                acl_data: RFC-compliant ACL Pydantic model

            Returns:
                FlextResult with OUD ACI formatted string including conversion comments

            Example:
                Input: Acl(name="Test", target=..., subject=..., permissions=...)
                Output: 'aci: (targetattr="*")(version 3.0; acl "Test"; allow (read) userdn="ldap:///self";)'

            """
            try:
                c = FlextLdifServersOud.Constants
                extensions = (
                    acl_data.metadata.extensions
                    if acl_data.metadata and acl_data.metadata.extensions
                    else None
                )

                # CONSOLIDATED: Conversion comments via utility (DRY)
                aci_output_lines = FlextLdifUtilities.ACL.format_conversion_comments(
                    extensions, MetaKeys.CONVERTED_FROM_SERVER, MetaKeys.CONVERSION_COMMENTS,
                )

                # Check if we should use raw_acl as-is
                if self._should_use_raw_acl(acl_data):
                    aci_output_lines.append(acl_data.raw_acl)
                    return FlextResult[str].ok("\n".join(aci_output_lines))

                # Build ACI parts
                aci_parts = [self._build_aci_target(acl_data)]

                # CONSOLIDATED: Target extensions via utility (DRY)
                aci_parts.extend(
                    FlextLdifUtilities.ACL.extract_target_extensions(
                        extensions, c.ACL_TARGET_EXTENSIONS_CONFIG,
                    )
                )

                # Version and ACL name
                acl_name = acl_data.name or c.ACL_DEFAULT_NAME
                aci_parts.append(f'({c.ACL_DEFAULT_VERSION}; acl "{acl_name}";')

                # Permissions
                perms_result = self._build_aci_permissions(acl_data)
                if perms_result.is_failure:
                    return FlextResult[str].fail(perms_result.error or "Unknown error")

                # Subject
                subject_str = self._build_aci_subject(acl_data)
                if not subject_str:
                    return FlextResult[str].fail("ACL subject DN was filtered out")

                # CONSOLIDATED: Bind rules via utility (DRY)
                bind_rules = FlextLdifUtilities.ACL.extract_bind_rules_from_extensions(
                    extensions, c.ACL_BIND_RULES_CONFIG, tuple_length=c.ACL_BIND_RULE_TUPLE_LENGTH,
                )
                if bind_rules:
                    subject_str = subject_str.rstrip(";)")
                    subject_str = f"{subject_str} and {' and '.join(bind_rules)};)"

                aci_parts.extend([perms_result.unwrap(), subject_str])

                # Build final ACI string
                aci_string = f"{c.ACL_ACI_PREFIX} {' '.join(aci_parts)}"
                aci_output_lines.append(aci_string)

                return FlextResult[str].ok("\n".join(aci_output_lines))

            except Exception as e:
                logger.exception(
                    "Failed to write ACL to RFC",
                )
                return FlextResult[str].fail(f"Failed to write ACL to RFC: {e}")

        @staticmethod
        def _is_aci_start(line: str) -> bool:
            """Check if line starts an ACI definition.

            Args:
                line: Stripped line to check

            Returns:
                True if line starts with 'aci:' (case-insensitive)

            """
            return line.lower().startswith(
                FlextLdifServersOud.Constants.ACL_ACI_PREFIX.lower(),
            )

        @staticmethod
        def _is_ds_cfg_acl(line: str) -> bool:
            """Check if line is a ds-cfg ACL format.

            Args:
                line: Stripped line to check

            Returns:
                True if line starts with 'ds-cfg-' (case-insensitive)

            """
            return line.lower().startswith(
                FlextLdifServersOud.Constants.ACL_DS_CFG_PREFIX.lower(),
            )

        def _finalize_aci(
            self,
            current_aci: list[str],
            acls: list[FlextLdifModels.Acl],
        ) -> None:
            """Parse and add accumulated ACI to ACL list.

            Args:
                current_aci: List of accumulated ACI lines
                acls: Target list to append parsed ACL

            """
            if current_aci:
                aci_text = "\n".join(current_aci)
                result = self.parse(aci_text)
                if result.is_success:
                    acls.append(result.unwrap())

        def extract_acls_from_ldif(
            self,
            ldif_content: str,
        ) -> FlextResult[list[FlextLdifModels.Acl]]:
            """Extract and parse all ACL definitions from LDIF content.

            Strategy pattern: OUD-specific approach to extract ACIs from LDIF entries.

            Args:
            ldif_content: Raw LDIF content containing ACL definitions

            Returns:
            FlextResult with list of parsed ACL models

            """
            try:
                acls: list[FlextLdifModels.Acl] = []
                current_aci: list[str] = []
                in_multiline_aci = False

                for line in ldif_content.split("\n"):
                    stripped = line.strip()

                    # Detect ACI start using helper
                    if self._is_aci_start(stripped):
                        # Finalize any previous ACI
                        self._finalize_aci(current_aci, acls)
                        current_aci = []

                        current_aci.append(stripped)
                        # Check if this ACI continues on next lines (no closing parenthesis)
                        in_multiline_aci = not stripped.rstrip().endswith(")")

                    elif in_multiline_aci and stripped:
                        # Continuation of multiline ACI
                        current_aci.append(stripped)
                        if stripped.rstrip().endswith(")"):
                            in_multiline_aci = False

                    elif self._is_ds_cfg_acl(stripped):
                        # Handle ds-cfg format directly
                        result = self.parse(stripped)
                        if result.is_success:
                            acls.append(result.unwrap())

                # Parse any remaining ACI
                self._finalize_aci(current_aci, acls)

                return FlextResult[list[FlextLdifModels.Acl]].ok(acls)

            except Exception as e:
                logger.exception(
                    "OUD ACL extraction failed",
                )
                return FlextResult[list[FlextLdifModels.Acl]].fail(
                    f"OUD ACL extraction failed: {e}",
                )

    class Entry(FlextLdifServersRfc.Entry):
        """Oracle OUD entry quirk (nested).

        Handles OUD-specific entry transformations:
        - OUD-specific operational attributes (ds-cfg-*, ds-sync-*, ds-pwp-*)
        - OUD entry formatting with case normalization
        - Entry transformations via RFC Entry Model metadata (no direct OID knowledge)

        Note: OUD has ZERO knowledge of OID formats. All OID→OUD conversions
        go through RFC Entry Model as intermediate format.

        Example:
            quirk = FlextLdifServersOud.Entry()
            if quirk.can_handle_entry(entry):
                result = quirk.parse_entry(entry.dn.value, entry.attributes.attributes)

        """

        def __init__(
            self,
            entry_service: object | None = None,
            **kwargs: object,
        ) -> None:
            """Initialize OUD entry quirk.

            Args:
                entry_service: Injected FlextLdifEntry service (optional)
                **kwargs: Passed to parent for compatibility

            """
            super().__init__(entry_service=entry_service, **kwargs)

        # OVERRIDDEN METHODS (from FlextLdifServersBase.Entry)
        # These methods override the base class with Oracle OUD-specific logic:
        # - can_handle(): Detects OUD entries by DN/attributes (PRIVATE)
        # - _parse_entry(): Normalizes OUD entries with metadata during parsing (PRIVATE)
        # - _write_entry(): Writes OUD entries with proper formatting (PRIVATE)

        def can_handle(
            self,
            entry_dn: str,
            attributes: Mapping[str, object],
        ) -> bool:
            """Check if OUD should handle this entry using pattern matching.

            Delegates to generic utility with OUD-specific patterns from Constants.

            Args:
                entry_dn: Entry DN string
                attributes: Entry attributes dictionary

            Returns:
                True if this quirk should handle the entry

            """
            c = FlextLdifServersOud.Constants
            return FlextLdifUtilities.Entry.matches_server_patterns(
                entry_dn,
                attributes,
                dn_patterns=c.DN_DETECTION_PATTERNS,
                attr_prefixes=c.DETECTION_ATTRIBUTE_PREFIXES,
                attr_names=c.BOOLEAN_ATTRIBUTES,
                keyword_patterns=c.KEYWORD_PATTERNS,
            ) or FlextLdifConstants.DictKeys.OBJECTCLASS.lower() in attributes

        def _process_oud_attributes(
            self,
            entry: FlextLdifModels.Entry,
        ) -> tuple[dict[str, list[str]], dict[str, list[str]]]:
            """Process OUD attributes: preserve internal + normalize regular in one pass.

            Returns:
                Tuple of (internal_attributes, normalized_attributes)

            """
            attrs_dict = entry.attributes.attributes if entry.attributes else {}
            if not attrs_dict:
                return {}, {}

            # Separate internal and regular attributes in single pass
            internal_keys = {"_base64_attrs", "_modify_add_attributetypes", "_modify_add_objectclasses"}
            internal = {k: v for k, v in attrs_dict.items() if k in internal_keys}
            regular = {k: v for k, v in attrs_dict.items() if not k.startswith("_")}

            # Normalize regular attributes using utilities
            normalized = (
                FlextLdifUtilities.Entry.convert_boolean_attributes(
                    FlextLdifUtilities.Entry.normalize_attribute_names(
                        FlextLdifUtilities.Entry.convert_boolean_attributes(
                            regular, set()
                        ),
                        dict(FlextLdifServersOud.Constants.ATTRIBUTE_CASE_MAP),
                    ),
                    set(FlextLdifServersOud.Constants.BOOLEAN_ATTRIBUTES),
                )
                if regular
                else {}
            )
            return internal, normalized

        def _build_and_populate_roundtrip_metadata(
            self,
            entry: FlextLdifModels.Entry,
            normalized_attributes: dict[str, list[str]],
            entry_dn: str,
        ) -> FlextLdifModels.QuirkMetadata:
            """Build metadata extensions and populate roundtrip metadata in one pass.

            Returns:
                Configured QuirkMetadata with all roundtrip information

            """
            original_attrs = entry.attributes.attributes if entry.attributes else {}
            dn_str = entry.dn.value if entry.dn else ""

            # Build metadata extensions using utility
            ext = FlextLdifUtilities.Metadata.build_entry_metadata_extensions(
                entry_dn=dn_str,
                original_attributes=original_attrs,
                processed_attributes=normalized_attributes,
                server_type="oud",
                metadata_keys=FlextLdifConstants.MetadataKeys,
                operational_attributes=list(FlextLdifServersOud.Constants.OPERATIONAL_ATTRIBUTES),
            )

            # Add OUD-specific quirks
            if (
                entry.dn
                and FlextLdifUtilities.DN.contains_pattern(entry.dn.value, ", ")
            ):
                ext["dn_spaces"] = True
            if normalized_attributes:
                ext["attribute_order"] = list(normalized_attributes.keys())

            # Create metadata and populate original attribute case in one operation
            new_metadata = FlextLdifModels.QuirkMetadata.create_for(
                "oud", extensions=ext
            )

            # Populate original case mappings
            for attr_name in original_attrs:
                if (
                    normalized := FlextLdifServersOud.Constants.ATTRIBUTE_CASE_MAP.get(
                        attr_name.lower(), attr_name
                    )
                ) != attr_name:
                    new_metadata.original_attribute_case[normalized] = attr_name

            # Populate objectClass case and metadata details
            if oc_list := original_attrs.get("objectClass"):
                for oc in (
                    oc_list
                    if isinstance(oc_list, list)
                    else [oc_list]
                ):
                    oc_str = oc if isinstance(oc, str) else str(oc)
                    if oc_str != (oc_lower := oc_str.lower()):
                        new_metadata.original_format_details[
                            f"objectclass_case_{oc_lower}"
                        ] = oc_str

            new_metadata.original_format_details["server_type"] = "oud"
            new_metadata.original_format_details["dn_spacing"] = entry_dn
            return new_metadata

        # ===== _parse_entry HELPER METHODS (DRY refactoring) =====
        # NOTE: _analyze_oud_entry_differences REMOVED - use FlextLdifUtilities.Entry.analyze_differences
        # NOTE: _store_oud_minimal_differences REMOVED - use FlextLdifUtilities.Metadata.store_minimal_differences

        def _parse_entry(
            self,
            entry_dn: str,
            entry_attrs: Mapping[str, object],
        ) -> FlextResult[FlextLdifModels.Entry]:
            """Parse raw LDIF entry data into Entry model with OUD-specific transformations.

            Applies OUD-specific normalizations during parsing:
            - Normalize attribute names to proper camelCase
            - Convert boolean attributes from 0/1 to TRUE/FALSE
            - Validate telephone numbers
            - Preserve metadata for DN quirks and attribute ordering

            Args:
                entry_dn: Raw DN string from LDIF parser
                entry_attrs: Raw attributes mapping from LDIF parser

            Returns:
                FlextResult with parsed Entry model with OUD-specific transformations

            """
            base_result = super()._parse_entry(entry_dn, entry_attrs)
            if base_result.is_failure:
                return base_result

            entry = base_result.unwrap()

            try:
                # Extract original lines from metadata for later storage
                original_dn_line, original_attr_lines_or_none = (
                    FlextLdifUtilities.Metadata.extract_original_lines_from_entry(
                        entry.metadata,
                    )
                )
                original_attr_lines = original_attr_lines_or_none or []
                original_entry_dict = dict(entry_attrs)

                # Process OUD attributes (separate internal + normalize regular)
                internal_attrs, normalized_attrs = self._process_oud_attributes(entry)

                # Combine internal and normalized attributes
                combined_attributes = normalized_attrs.copy()
                combined_attributes.update(internal_attrs)
                new_ldif_attributes = FlextLdifModels.LdifAttributes(
                    attributes=combined_attributes,
                )

                # Analyze differences between original and processed
                original_dn = entry_dn
                parsed_dn = entry.dn.value if entry.dn else None
                dn_differences, attribute_differences, original_attrs_complete, _ = (
                    FlextLdifUtilities.Entry.analyze_differences(
                        entry_attrs=original_entry_dict,
                        converted_attrs=normalized_attrs,
                        original_dn=original_dn,
                        cleaned_dn=parsed_dn or original_dn,
                    )
                )

                # Build and populate roundtrip metadata in one operation
                new_metadata = self._build_and_populate_roundtrip_metadata(
                    entry, normalized_attrs, entry_dn
                )
                new_metadata.extensions["original_entry"] = entry

                # Store all differences using utility
                FlextLdifUtilities.Metadata.store_minimal_differences(
                    metadata=new_metadata,
                    dn_differences=dn_differences,
                    attribute_differences=attribute_differences,
                    original_dn=original_dn,
                    parsed_dn=parsed_dn,
                    original_attributes_complete=original_attrs_complete,
                    original_dn_line=original_dn_line,
                    original_attr_lines=original_attr_lines,
                )

                logger.debug(
                    "OUD entry parsed",
                    entry_dn=original_dn[:50] if original_dn else None,
                    attrs_count=(len(original_entry_dict), len(normalized_attrs)),
                    has_differences=(bool(dn_differences.get("has_differences")), len(attribute_differences) > 0),
                )

                if entry.dn is None:
                    return FlextResult.fail("Entry DN cannot be None for OUD parsing")

                entry_create_result = FlextLdifModels.Entry.create(
                    dn=entry.dn,
                    attributes=new_ldif_attributes,
                    metadata=new_metadata,
                )
                if entry_create_result.is_failure:
                    return FlextResult.fail(
                        entry_create_result.error or "Failed to create entry"
                    )
                entry_unwrapped = entry_create_result.unwrap()
                if not isinstance(entry_unwrapped, FlextLdifModels.Entry):
                    msg = f"Expected Entry, got {type(entry_unwrapped)}"
                    raise TypeError(msg)
                return FlextResult.ok(entry_unwrapped)

            except Exception as e:
                return FlextResult.fail(f"OUD entry parsing failed: {e}")

        def _format_aci_with_semicolons(self, aci_value: str) -> str:
            """Format ACI value with semicolons between multiple 'by' clauses for OUD.

            OUD requires semicolons (;) to separate multiple 'by' clauses in ACI.

            Example:
              Input:  "aci: access to entry by group=... (...) by group=... (...) by * (...)"
              Output: "aci: access to entry by group=... (...) ; by group=... (...) ; by * (...)"

            Args:
                aci_value: ACI value string (may be multiline)

            Returns:
                Formatted ACI with semicolons inserted after each 'by' clause (except last)

            """
            # CRITICAL: This method only does semantic transformation (add semicolons).
            # Line formatting (folding/unfolding) is the writer's responsibility, NOT the quirk's.
            # Always normalize whitespace and remove newlines - let writer handle formatting.

            # Normalize whitespace: replace all whitespace (including newlines) with single spaces)
            # This ensures the quirk only does semantic transformation, not formatting
            normalized = re.sub(r"\s+", " ", aci_value.strip())

            # OUD format requires semicolons after each "by" clause (except the last one)
            # Format: "by group=\"...\" ;" or "by *" (no semicolon if last)
            # Find all "by group=\"...\"" and "by *" clauses
            by_group_pattern = FlextLdifServersOud.Constants.ACL_BY_GROUP_PATTERN
            by_star_pattern = FlextLdifServersOud.Constants.ACL_BY_STAR_PATTERN

            # Find all by clauses with their end positions
            by_clauses = [
                (match.end(), "group")
                for match in re.finditer(by_group_pattern, normalized, re.IGNORECASE)
            ]
            by_clauses.extend(
                (match.end(), "star")
                for match in re.finditer(by_star_pattern, normalized, re.IGNORECASE)
            )

            # Sort by position (first element of tuple)
            by_clauses.sort(key=operator.itemgetter(0))

            if len(by_clauses) <= 1:
                # Only one or zero "by" clauses - no formatting needed, but still normalize whitespace
                return normalized

            # Insert semicolons after each "by" clause except the last one
            # Check if each is followed by (permissions) by next_clause
            result_parts = []
            last_pos = 0

            for i, (pos, _clause_type) in enumerate(by_clauses):
                # Add text up to this position
                result_parts.append(normalized[last_pos:pos])

                # Check if this is NOT the last clause and is followed by (permissions) by
                if i < len(by_clauses) - 1:
                    # Check what comes after this clause
                    next_text = normalized[pos : min(len(normalized), pos + 100)]
                    # Pattern: space(s) followed by (permissions) followed by space(s) and "by"
                    if re.search(r"^\s+\([^)]+\)\s+by\s+", next_text, re.IGNORECASE):
                        # Add semicolon after the closing quote or *
                        result_parts.append(" ;")

                last_pos = pos

            # Add remaining text
            result_parts.append(normalized[last_pos:])

            return "".join(result_parts)

        def _is_schema_entry(self, entry: FlextLdifModels.Entry) -> bool:
            """Check if entry is a schema entry - delegate to utility."""
            return FlextLdifUtilities.Entry.is_schema_entry(entry, strict=False)

        def _write_entry_modify_add_format(
            self,
            entry_data: FlextLdifModels.Entry,
            allowed_schema_oids: frozenset[str] | None = None,
        ) -> FlextResult[str]:
            """Write schema entry in OUD modify-add format.

            Delegates to shared helper method to avoid code duplication.
            See FlextLdifServersOud._write_entry_modify_add_format_helper for full documentation.

            Args:
                entry_data: Schema entry to write
                allowed_schema_oids: Optional set of allowed OIDs for filtering

            Returns:
                FlextResult with LDIF string (multiple entries, one per schema element)

            """
            # Get parent_quirk from Entry instance (set during __init__ in base.py)
            # If not available, create new OUD instance to access schema_quirk
            parent_quirk: object | None = getattr(self, "parent_quirk", None)
            if parent_quirk is None:
                parent_quirk = getattr(self, "_parent_quirk", None)
            if parent_quirk is None:
                # Fallback: create OUD instance to access schema_quirk
                parent_quirk = FlextLdifServersOud()

            return FlextLdifServersOud._write_entry_modify_add_format_helper(
                entry_data,
                allowed_schema_oids,
                parent_quirk,
            )

        def _add_original_entry_comments(
            self,
            entry_data: FlextLdifModels.Entry,
            write_options: FlextLdifModels.WriteFormatOptions | None,
        ) -> list[str]:
            """Add original entry as commented LDIF block.

            Args:
                entry_data: Entry with metadata containing original entry
                write_options: Write options with write_original_entry_as_comment flag

            Returns:
                List of LDIF comment lines (empty if feature disabled)

            """
            if not (write_options and write_options.write_original_entry_as_comment):
                return []

            # RFC Compliance: Check metadata.write_options
            if not entry_data.metadata.write_options:
                return []

            original_entry_obj = entry_data.metadata.write_options.get(
                MetaKeys.ORIGINAL_ENTRY,
            )
            if not (
                original_entry_obj
                and isinstance(original_entry_obj, FlextLdifModels.Entry)
            ):
                return []

            ldif_parts: list[str] = []
            ldif_parts.extend(
                [
                    "# " + "=" * 70,
                    "# ORIGINAL Entry (alternative format) (commented)",
                    "# " + "=" * 70,
                ],
            )

            original_result = self._write_entry_as_comment(original_entry_obj)
            if original_result.is_success:
                ldif_parts.append(original_result.unwrap())

            ldif_parts.extend(
                [
                    "",
                    "# " + "=" * 70,
                    "# CONVERTED OUD Entry (active)",
                    "# " + "=" * 70,
                ],
            )

            return ldif_parts

        def _apply_phase_aware_acl_handling(
            self,
            entry_data: FlextLdifModels.Entry,
            write_options: FlextLdifModels.WriteFormatOptions | None,
        ) -> FlextLdifModels.Entry:
            """Apply phase-aware ACL attribute commenting.

            Args:
                entry_data: Entry to process
                write_options: Write options with ACL phase settings

            Returns:
                Entry with ACL attributes commented if applicable

            """
            if not (write_options and write_options.comment_acl_in_non_acl_phases):
                return entry_data

            category = write_options.entry_category
            acl_attrs = write_options.acl_attribute_names

            if not (category and category != "acl" and acl_attrs):
                return entry_data

            # Comment out ACL attributes in non-ACL phases (01/02/03)
            return FlextLdifServersOud._comment_acl_attributes_static(entry_data, acl_attrs)

        def _normalize_aci_value(
            self,
            aci_value: str,
            base_dn: str | None,
            dn_registry: FlextLdifModels.DnRegistry | None,
        ) -> tuple[str, bool]:
            """Normalize ACI value DNs using utilities for cleaning and filtering."""
            dn_was_filtered = [False]

            def normalize_dn(
                dn_value: str,
                original: str,
            ) -> tuple[str, bool]:
                """Normalize DN: clean, resolve case, filter by base."""
                cleaned = FlextLdifUtilities.DN.clean_dn(dn_value)
                if dn_registry and (canon := dn_registry.get_canonical_dn(cleaned)):
                    cleaned = canon
                if base_dn and cleaned and not FlextLdifUtilities.DN.is_under_base(
                    cleaned, base_dn
                ):
                    dn_was_filtered[0] = True
                    return original, True
                return cleaned, False

            def replace_rfc(match: re.Match[str]) -> str:
                prefix = match.group(2) or ""
                dn, filtered = normalize_dn(match.group(3), match.group(0))
                return match.group(0) if filtered else f'{match.group(1)}="{prefix}{dn}"'

            def replace_oid(match: re.Match[str]) -> str:
                dn, filtered = normalize_dn(match.group(2), match.group(0))
                return match.group(0) if filtered else f'by {match.group(1)}="{dn}"'

            result = re.sub(r'(userdn|groupdn)="(ldap:///)?([^"]+)"', replace_rfc, aci_value)
            result = re.sub(r'by\s+(group|dn)="([^"]+)"', replace_oid, result)
            return result, dn_was_filtered[0]

        def _extract_acl_metadata(
            self,
            entry_data: FlextLdifModels.Entry,
        ) -> tuple[str | None, FlextLdifModels.DnRegistry | None]:
            """Extract base_dn and dn_registry from entry metadata for ACL processing.

            Args:
                entry_data: Entry with potential metadata

            Returns:
                Tuple of (base_dn, dn_registry)

            """
            base_dn: str | None = None
            dn_registry: FlextLdifModels.DnRegistry | None = None

            if entry_data.metadata.write_options:
                # Try write_options first
                base_dn_value = entry_data.metadata.write_options.get("base_dn")
                if isinstance(base_dn_value, str):
                    base_dn = base_dn_value

                # Get dn_registry from write_options
                dn_registry_value = entry_data.metadata.write_options.get("dn_registry")
                if isinstance(dn_registry_value, FlextLdifModels.DnRegistry):
                    dn_registry = dn_registry_value

            # Try extensions if write_options doesn't have base_dn
            if base_dn is None and entry_data.metadata.extensions:
                extensions = entry_data.metadata.extensions
                if FlextRuntime.is_dict_like(extensions):
                    base_dn_ext = extensions.get("base_dn")
                    if isinstance(base_dn_ext, str):
                        base_dn = base_dn_ext
                    dn_registry_ext = extensions.get("dn_registry")
                    if isinstance(dn_registry_ext, FlextLdifModels.DnRegistry):
                        dn_registry = dn_registry_ext

            return base_dn, dn_registry

        def _normalize_acl_dns(
            self,
            entry_data: FlextLdifModels.Entry,
        ) -> FlextLdifModels.Entry:
            """Normalize and filter DNs in ACL attribute values (userdn/groupdn inside ACL strings).

            Processes ACL values (aci attribute) to:
            - Normalize DNs: remove spaces after commas, preserve case
            - Filter DNs by base_dn if provided (from entry metadata)

            Args:
                entry_data: Entry with potential ACL attributes

            Returns:
                Entry with normalized/filtered ACL values

            """
            if not entry_data.attributes or not entry_data.attributes.attributes:
                return entry_data

            # Extract base_dn and dn_registry from metadata
            base_dn, dn_registry = self._extract_acl_metadata(entry_data)

            # Process aci attribute values
            attrs = entry_data.attributes.attributes
            if "aci" not in attrs:
                return entry_data

            aci_values = attrs["aci"]
            if not aci_values:
                return entry_data

            # Normalize each ACL value string
            normalized_aci_values: list[str] = []
            for aci in aci_values:
                aci_str = aci if isinstance(aci, str) else str(aci)
                normalized_aci, was_filtered = self._normalize_aci_value(
                    aci_str,
                    base_dn,
                    dn_registry,
                )

                # Only add if no DN was filtered out (ACL is still valid)
                if not was_filtered and normalized_aci:
                    normalized_aci_values.append(normalized_aci)

            # Update entry with normalized ACL values
            if normalized_aci_values != aci_values:
                new_attrs = dict(entry_data.attributes.attributes)
                new_attrs["aci"] = normalized_aci_values
                entry_data.attributes.attributes = new_attrs

            return entry_data

        def _restore_entry_from_metadata(
            self,
            entry_data: FlextLdifModels.Entry,
        ) -> FlextLdifModels.Entry:
            """Restore original DN and attributes using generic utilities."""
            if not (entry_data.metadata and entry_data.metadata.extensions):
                return entry_data
            ext = entry_data.metadata.extensions

            # Restore DN if differences detected
            if (
                original_dn := ext.get("original_dn_complete")
            ) and isinstance(original_dn, str) and entry_data.dn:
                dn_diff = ext.get("minimal_differences_dn", {})
                if FlextRuntime.is_dict_like(dn_diff) and dn_diff.get("has_differences"):
                    entry_data = entry_data.model_copy(
                        update={"dn": FlextLdifModels.DistinguishedName(value=original_dn)}
                    )

            # Restore attributes if case mapping available
            if (
                entry_data.attributes
                and entry_data.metadata.original_attribute_case
                and (orig_attrs := ext.get("original_attributes_complete"))
                and FlextRuntime.is_dict_like(orig_attrs)
            ):
                restored: dict[str, list[str]] = {}
                for attr_name, attr_values in entry_data.attributes.attributes.items():
                    orig_case = entry_data.metadata.original_attribute_case.get(
                        attr_name.lower(), attr_name
                    )
                    if orig_case in orig_attrs:
                        val = orig_attrs[orig_case]
                        restored[orig_case] = (
                            [str(i) for i in val] if FlextRuntime.is_list_like(val) else [str(val)]
                        )
                    else:
                        restored[orig_case] = [str(i) for i in attr_values] if isinstance(attr_values, list) else [str(attr_values)]

                if restored:
                    entry_data = entry_data.model_copy(
                        update={
                            "attributes": FlextLdifModels.LdifAttributes(
                                attributes=restored,
                                attribute_metadata=entry_data.attributes.attribute_metadata,
                                metadata=entry_data.attributes.metadata,
                            )
                        }
                    )

            return entry_data

        def _extract_write_options(
            self,
            entry_data: FlextLdifModels.Entry,
        ) -> FlextLdifModels.WriteFormatOptions | None:
            """Extract write options from entry metadata."""
            if not entry_data.metadata.write_options:
                return None

            write_options_obj = entry_data.metadata.write_options.get(
                MetaKeys.WRITE_OPTIONS,
            )
            if isinstance(write_options_obj, FlextLdifModels.WriteFormatOptions):
                return write_options_obj
            return None

        def _write_entry(
            self,
            entry_data: FlextLdifModels.Entry,
        ) -> FlextResult[str]:
            """Write Entry to LDIF with OUD-specific formatting + phase-aware ACL handling.

            CRITICAL: Uses metadata to restore original OUD formatting for perfect round-trip.
            Restores DN, attributes, case, spacing, punctuation, etc. from metadata.

            Features:
            1. Schema entries: OUD modify-add format (OUD requirement)
            2. Original entry commenting: Write source entry as commented LDIF block
            3. Phase-aware ACL handling: Comment ACL attributes in non-ACL phases
            4. Standard entries: RFC format (with original formatting restored from metadata)

            Args:
                entry_data: Entry model to write (with complete metadata)

            Returns:
                FlextResult with LDIF string (with original formatting restored when possible)

            """
            # Restore original formatting from metadata
            entry_to_write = self._restore_entry_from_metadata(entry_data)

            # Extract write options
            write_options = self._extract_write_options(entry_to_write)

            # Build LDIF output
            ldif_parts: list[str] = []
            ldif_parts.extend(
                self._add_original_entry_comments(entry_data, write_options),
            )

            # Apply phase-aware ACL handling
            entry_data = self._apply_phase_aware_acl_handling(entry_data, write_options)

            # Normalize DNs in ACL values if enabled
            if FlextLdifServersOud.Constants.ACL_NORMALIZE_DNS_IN_VALUES:
                entry_data = self._normalize_acl_dns(entry_data)

            # Write entry in appropriate format
            if self._is_schema_entry(entry_data):
                allowed_oids: frozenset[str] | None = None
                if write_options:
                    allowed_oids = getattr(write_options, "allowed_schema_oids", None)
                result = self._write_entry_modify_add_format(entry_data, allowed_oids)
            else:
                result = super()._write_entry(entry_data)

            if result.is_failure:
                return result

            ldif_parts.append(result.unwrap())
            return FlextResult[str].ok("\n".join(ldif_parts))

        def _write_entry_as_comment(
            self,
            entry_data: FlextLdifModels.Entry,
        ) -> FlextResult[str]:
            """Write entry as commented LDIF (each line prefixed with '# ').

            Args:
                entry_data: Entry to write as comment

            Returns:
                FlextResult with commented LDIF string

            """
            # Use RFC write method to get LDIF representation
            result = super()._write_entry(entry_data)
            if result.is_failure:
                return result

            # Prefix each line with '# '
            ldif_text = result.unwrap()
            commented_lines = [f"# {line}" for line in ldif_text.split("\n")]
            return FlextResult[str].ok("\n".join(commented_lines))

        def write(
            self,
            entry_data: FlextLdifModels.Entry | list[FlextLdifModels.Entry],
            write_options: FlextLdifModels.WriteFormatOptions | None = None,
        ) -> FlextResult[str]:
            r"""Public API: Write OUD entry to LDIF format.

            Converts Entry model to LDIF format string.

            Flow:
            1. Call _hook_pre_write_entry() for OUD-specific validation/normalization
            2. Call parent RFC._write_entry() to handle LDIF output (including modify format)

            Args:
                entry_data: Entry model object (RFC canonical from parsing)

            Returns:
                FlextResult with LDIF formatted entry string

            """
            # Handle list of entries by delegating to parent
            if isinstance(entry_data, list):
                if self.parent_quirk is not None and hasattr(
                    self.parent_quirk, "write"
                ):
                    write_result = self.parent_quirk.write(entry_data, write_options)
                    # Type-safe extraction and re-wrapping
                    if write_result.is_success:
                        value = write_result.unwrap()
                        if isinstance(value, str):
                            return FlextResult[str].ok(value)
                        return FlextResult[str].ok(str(value))
                    return FlextResult[str].fail(write_result.error or "Write failed")
                # Fallback: write each entry and join
                results: list[str] = []
                for entry in entry_data:
                    result = self.write(entry, write_options)
                    if result.is_success:
                        unwrapped = result.unwrap()
                        results.append(unwrapped)
                    else:
                        return result
                return FlextResult[str].ok("\n\n".join(results))

            # Type narrowing: entry_data is already Entry model
            if not isinstance(entry_data, FlextLdifModels.Entry):
                msg = f"Expected Entry, got {type(entry_data)}"
                raise TypeError(msg)
            entry_model = entry_data
            write_opts = write_options

            # Step 1: Apply pre-write hook for OUD-specific normalization
            hook_result = self._hook_pre_write_entry(entry_model)
            if hook_result.is_failure:
                return FlextResult[str].fail(
                    f"Pre-write hook failed: {hook_result.error}",
                )

            normalized_entry = hook_result.unwrap()

            # Step 2: Check if modify format is requested
            if write_opts and write_opts.ldif_changetype == "modify":
                return self._write_entry_modify_format(normalized_entry, write_opts)

            # Step 3: Call OUD _write_entry() which handles schema entries specially
            # For schema entries, uses modify-add format
            # For other entries, delegates to RFC implementation
            return self._write_entry(normalized_entry)

        def _hook_post_parse_entry(
            self,
            entry: FlextLdifModels.Entry,
        ) -> FlextResult[FlextLdifModels.Entry]:
            """Hook: Validate OUD ACI macros after parsing Entry.

            When reading OUD LDIF, ACIs may contain macros that require validation:
            - ($dn): substring matching/substitution
            - [$dn]: hierarchical substitution
            - ($attr.attrName): attribute value substitution

            This hook validates macro consistency WITHOUT expanding them
            (runtime expansion happens in OUD directory server).

            Processing:
            1. Validate ACI macro rules if aci: attributes present
            2. Preserve macros as-is (RFC Entry canonical format)
            3. Add metadata notes if macros present

            Args:
                entry: Entry parsed from OUD LDIF (in RFC canonical format)

            Returns:
                FlextResult[Entry] - validated entry, unchanged if valid

            """
            # Extract attributes dict with None check for type safety
            attrs_dict = (
                entry.attributes.attributes if entry.attributes is not None else {}
            )

            # Validate ACI macros if present
            aci_attrs = attrs_dict.get("aci")
            if aci_attrs and FlextRuntime.is_list_like(aci_attrs):
                has_macros = False
                for aci_value in aci_attrs:
                    if isinstance(aci_value, str):
                        # Check if macros present
                        if re.search(r"\(\$dn\)|\[\$dn\]|\(\$attr\.", aci_value):
                            has_macros = True

                        # Validate macro rules
                        validation_result = self._validate_aci_macros(aci_value)
                        if validation_result.is_failure:
                            return FlextResult[FlextLdifModels.Entry].fail(
                                f"ACI macro validation failed: {validation_result.error}",
                            )

                # Log if macros were found (metadata is immutable - just log)
                if has_macros:
                    max_len = FlextLdifServersOud.Constants.MAX_LOG_LINE_LENGTH
                    aci_list = list(aci_attrs) if FlextRuntime.is_list_like(aci_attrs) else [str(aci_attrs)]
                    logger.debug(
                        "Entry contains OUD ACI macros - preserved for runtime expansion",
                        entry_dn=entry.dn.value if entry.dn else None,
                        aci_count=len(aci_list),
                        aci_preview=[s[:max_len] for s in aci_list[:FlextLdifConstants.ACI_LIST_PREVIEW_LIMIT] if isinstance(s, str)],
                    )

            # Entry is RFC-canonical - return unchanged
            return FlextResult[FlextLdifModels.Entry].ok(entry)

        def _validate_aci_macros(self, aci_value: str) -> FlextResult[bool]:
            """Validate OUD ACI macro consistency rules (no-op)."""
            # ACI syntax is validated at parse time
            return FlextResult[bool].ok(True)

        def _hook_pre_write_entry(
            self,
            entry: FlextLdifModels.Entry,
        ) -> FlextResult[FlextLdifModels.Entry]:
            """Hook: Pre-write entry validation (simplified).

            Entry is returned unchanged (RFC-valid format preserved).

            Args:
                entry: RFC Entry (already canonical)

            Returns:
                FlextResult[Entry] - entry unchanged

            """
            # Entry is RFC-canonical and already validated
            return FlextResult[FlextLdifModels.Entry].ok(entry)

        def _finalize_and_parse_entry(
            self,
            entry_dict: dict[str, object],
            entries_list: list[FlextLdifModels.Entry],
        ) -> None:
            """Finalize entry dict and parse into entries list.

            Args:
                entry_dict: Entry dictionary with DN and attributes
                entries_list: Target list to append parsed Entry models

            """
            if FlextLdifConstants.DictKeys.DN not in entry_dict:
                return

            dn = str(entry_dict.pop(FlextLdifConstants.DictKeys.DN))
            original_entry_dict = dict(entry_dict)

            result = self._parse_entry(dn, entry_dict)
            if result.is_success:
                entry = result.unwrap()
                original_dn = dn
                parsed_dn = entry.dn.value if entry.dn else None
                parsed_attrs = entry.attributes.attributes if entry.attributes else {}

                # CONSOLIDATED: Use utilities for difference analysis and storage (DRY)
                converted_attrs: dict[str, list[str]] = {
                    k: list(v) if isinstance(v, list) else [str(v)]
                    for k, v in parsed_attrs.items()
                }
                dn_differences, attribute_differences, original_attrs_complete, _ = (
                    FlextLdifUtilities.Entry.analyze_differences(
                        entry_attrs=original_entry_dict,
                        converted_attrs=converted_attrs,
                        original_dn=original_dn,
                        cleaned_dn=parsed_dn or original_dn,
                    )
                )

                # Ensure metadata exists
                if not entry.metadata:
                    entry.metadata = FlextLdifModels.QuirkMetadata.create_for(
                        "oud", extensions={},
                    )

                # CONSOLIDATED: Store via utility (DRY)
                FlextLdifUtilities.Metadata.store_minimal_differences(
                    metadata=entry.metadata,
                    dn_differences=dn_differences,
                    attribute_differences=attribute_differences,
                    original_dn=original_dn,
                    parsed_dn=parsed_dn,
                    original_attributes_complete=original_attrs_complete,
                )

                logger.debug(
                    "OUD entry parsed with minimal differences",
                    entry_dn=original_dn[:50] if original_dn else None,
                )

                entries_list.append(entry)

        def extract_entries_from_ldif(
            self,
            ldif_content: str,
        ) -> FlextResult[list[FlextLdifModels.Entry]]:
            """Extract and parse all directory entries from LDIF content.

            Strategy pattern: OUD-specific approach to extract entries from LDIF.

            Args:
                ldif_content: Raw LDIF content containing directory entries

            Returns:
                FlextResult with list of parsed Entry models (RFC canonical)

            """
            try:
                entries: list[FlextLdifModels.Entry] = []
                current_entry: dict[str, object] = {}
                current_attr: str | None = None
                current_values: list[str] = []

                for line in ldif_content.split("\n"):
                    # Empty line indicates end of entry
                    if not line.strip():
                        if current_entry:
                            # Finalize and process entry
                            FlextLdifUtilities.Parser.finalize_pending_attribute(
                                current_attr,
                                current_values,
                                current_entry,
                            )
                            self._finalize_and_parse_entry(current_entry, entries)
                            current_entry = {}
                            current_attr = None
                            current_values = []
                        continue

                    # Skip comments
                    if line.startswith("#"):
                        continue

                    # Continuation line (starts with space)
                    if line.startswith(" ") and current_attr and current_values:
                        current_values[-1] += line[1:]  # Remove leading space
                        continue

                    # Process new attribute line using utility
                    current_attr, current_values = (
                        FlextLdifUtilities.Parser.process_ldif_attribute_line(
                            line,
                            current_attr,
                            current_values,
                            current_entry,
                        )
                    )

                # Process final entry
                if current_entry:
                    FlextLdifUtilities.Parser.finalize_pending_attribute(
                        current_attr,
                        current_values,
                        current_entry,
                    )
                    self._finalize_and_parse_entry(current_entry, entries)

                return FlextResult[list[FlextLdifModels.Entry]].ok(entries)

            except Exception as e:
                logger.exception(
                    "OUD entry extraction failed",
                )
                return FlextResult[list[FlextLdifModels.Entry]].fail(
                    f"OUD entry extraction failed: {e}",
                )

        def _inject_validation_rules(
            self,
            entry: FlextLdifModels.Entry,
        ) -> FlextLdifModels.Entry:
            """Inject OUD-specific validation rules into Entry metadata (no-op)."""
            return entry


__all__ = ["FlextLdifServersOud"]
